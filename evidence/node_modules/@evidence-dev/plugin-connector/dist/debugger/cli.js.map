{"mappings":"A,O,W,C,K,W,A,Q,M,a,A,Q,M,M,A,Q,M,M,A,Q,M,O,A,Q,M,c,A,O,a,A,Q,K,C,K,K,A,Q,M,I,CIMA,IAAM,EAAyB,AAAA,EAAE,GAAG,GAAG,MAAM,CAC5C,AAAC,GAEA,EAAK,MAAM,OAAO,CAAC,KAGC,IAAhB,EAAK,MAAM,EACR,AAAA,EAAE,MAAM,CAAC,AAAA,EAAE,MAAM,GAAI,AAAA,EAAE,GAAG,IAAI,SAAS,CAAC,CAAI,CAAC,EAAE,EAAE,OAAO,EAEhE,CAAE,QAAS,sCAAuC,GAE7C,EAA6B,AAAA,EAAE,QAAQ,GAEhC,EAAoB,AAAA,EAC/B,MAAM,CAAC,CAKP,KAAM,EAAuB,EAAE,CAAC,GAChC,YAAa,AAAA,EAAE,KAAK,CACnB,AAAA,EAAE,MAAM,CAAC,CACR,KAAM,AAAA,EAAE,MAAM,GACd,aAAc,AAAA,EAAE,IAAI,CAAC,CAAC,UAAW,SAAU,SAAU,OAAO,EAC5D,aAAc,AAAA,EAAE,KAAK,CAAC,CAAC,AAAA,EAAE,OAAO,CAAC,WAAY,AAAA,EAAE,OAAO,CAAC,YAAY,CACpE,IAED,iBAAkB,AAAA,EAAE,MAAM,GAAG,QAAQ,EACtC,GACC,MAAM,CACN,AAAC,IAEA,GAAI,AAAqB,YAArB,OAAO,EAAK,IAAI,CAAiB,MAAO,CAAA,EAE5C,IAAM,EAAO,EAAK,IAAI,OAGlB,CAAA,EAAK,MAAM,GAQV,AAJmB,EAAK,WAAW,CACrC,MAAM,CAAC,AAAC,GAAO,CAAE,CAAA,EAAG,IAAI,IAAI,CAAI,CAAC,EAAE,AAAF,GACjC,GAAG,CAAC,AAAC,GAAO,EAAG,IAAI,EAEF,MAAM,AAK3B,EACA,AAAC,IAEA,GAAI,AAAqB,YAArB,OAAO,EAAK,IAAI,CACnB,MAAO,CACN,KAAM,CAAC,cAAc,AACtB,EACD,IAAM,EAAO,EAAK,IAAI,CAEhB,EAAiB,EAAK,WAAW,CACrC,MAAM,CAAC,AAAC,GAAO,CAAE,CAAA,EAAG,IAAI,IAAI,CAAI,CAAC,EAAE,AAAF,GACjC,GAAG,CAAC,AAAC,GAAO,EAAG,IAAI,EACrB,MAAO,CACN,KAAM,CAAC,cAAc,CACrB,QAAS,CAAC,sEAAsE,EAAE,EAAe,IAAI,CACpG,MACC,CAAC,AACJ,CACD,GAEA,MAAM,CACN,AAAC,IAEA,GAAI,AAAqB,YAArB,OAAO,EAAK,IAAI,CAAiB,MAAO,CAAA,EAG5C,GAAI,EAAK,IAAI,CAAC,MAAM,CAAE,CACrB,IAAM,EAAW,EAAK,WAAW,CAAC,GAAG,CAAC,AAAC,GAAO,EAAG,IAAI,EAIrD,GAAI,AAHiB,OAAO,IAAI,CAAC,EAAK,IAAI,CAAC,EAAE,EAAE,MAAM,CACpD,AAAC,GAAW,CAAC,EAAS,QAAQ,CAAC,IAEf,MAAM,CACtB,MAAO,CAAA,CAET,CACA,MAAO,CAAA,CACR,EACA,AAAC,IAEA,GAAI,AAAqB,YAArB,OAAO,EAAK,IAAI,CACnB,MAAO,CACN,KAAM,CAAC,OAAO,AACf,EAED,IAAM,EAAW,EAAK,WAAW,CAAC,GAAG,CAAC,AAAC,GAAO,EAAG,IAAI,EAC/C,EAAe,OAAO,IAAI,CAAC,EAAK,IAAI,CAAC,EAAE,EAAE,MAAM,CAAC,AAAC,GAAW,CAAC,EAAS,QAAQ,CAAC,IACrF,MAAO,CACN,KAAM,CAAC,OAAO,CACd,QAAS,CAAC,0DAA0D,EAAE,EAAa,IAAI,CACtF,MACC,CAAC,AACJ,CACD,GAGW,EAAoB,AAAA,EAC/B,QAAQ,GACR,IAAI,CACJ,AAAA,EAAE,MAAM,CAAC,CAAE,YAAa,aAAc,GAAG,EAAE,CAAC,AAAA,EAAE,IAAI,CAAC,CAAE,YAAa,yBAA0B,IAC5F,AAAA,EAAE,MAAM,CAAC,CAAE,YAAa,eAAgB,GACxC,AAAA,EAAE,MAAM,CAAC,CAAE,YAAa,YAAa,GAAG,EAAE,CAAC,AAAA,EAAE,IAAI,KAEjD,OAAO,CAAC,AAAA,EAAE,OAAO,CAAC,EAAkB,EAAE,CAAC,AAAA,EAAE,IAAI,KAAK,EAAE,CAAC,IAE1C,EAAyB,AAAA,EACpC,QAAQ,GACR,IAAI,CAAC,AAAA,EAAE,GAAG,CAAC,CAAE,YAAa,oBAAqB,IAC/C,OAAO,CAAC,AAAA,EAAE,OAAO,CAAC,AAAA,EAAE,KAAK,CAAC,CAAC,AAAA,EAAE,OAAO,CAAC,CAAA,GAAO,AAAA,EAAE,MAAM,CAAC,CAAE,OAAQ,AAAA,EAAE,MAAM,EAAG,GAAG,IAElE,EAAmC,AAAA,EAC9C,QAAQ,GACR,IAAI,CACJ,AAAA,EAAE,GAAG,CAAC,CAAE,YAAa,oBAAqB,GAC1C,AAAA,EAAE,MAAM,CAAC,CAAE,YAAa,sBAAuB,IAE/C,OAAO,CAAC,AAAA,EAAE,OAAO,CAAC,IAed,EAAY,AAAA,EAAE,KAAK,CAAC,CAAC,AAAA,EAAE,MAAM,GAAI,AAAA,EAAE,MAAM,GAAI,AAAA,EAAE,OAAO,GAAG,EAGlD,EAA6B,AAAA,EAAE,MAAM,CACjD,AAAA,EAAE,MAAM,GACR,AAAA,EAAE,MAAM,CAAC,CACR,MAAO,AAAA,EAAE,MAAM,GACf,KAAM,AAAA,EAAE,IAAI,CAAC,CAAC,SAAU,SAAU,UAAW,SAAU,OAAO,EAC9D,OAAQ,AAAA,EAAE,OAAO,GAAG,OAAO,CAAC,CAAA,GAC5B,MAAO,AAAA,EAAE,OAAO,GAAG,QAAQ,GAI3B,QAAS,AAAA,EAAE,OAAO,GAAG,OAAO,CAAC,CAAA,GAI7B,WAAY,AAAA,EAAE,MAAM,GAAG,QAAQ,GAI/B,eAAgB,AAAA,EAAE,OAAO,GAAG,OAAO,CAAC,CAAA,GACpC,WAAY,AAAA,EAAE,IAAI,CAAC,CAAC,OAAQ,OAAO,EAAE,QAAQ,GAC7C,YAAa,AAAA,EAAE,MAAM,GAAG,QAAQ,GAChC,SAAU,AAAA,EAAE,IAAI,CAAC,IAAM,AAAA,EAAE,MAAM,CAAC,AAAA,EAAE,MAAM,GAAI,IAA6B,QAAQ,GACjF,SAAU,AAAA,EAAE,OAAO,GAAG,OAAO,CAAC,CAAA,GAC9B,QAAS,AAAA,EACP,KAAK,CAAC,CAAC,AAAA,EAAE,MAAM,GAAI,AAAA,EAAE,MAAM,CAAC,CAAE,MAAO,EAAW,MAAO,AAAA,EAAE,MAAM,EAAG,GAAG,EACrE,KAAK,GACL,QAAQ,GACV,KAAM,AAAA,EAAE,OAAO,GAAG,QAAQ,GAC1B,QAAS,EAAU,QAAQ,EAC5B,IAGY,EAA4B,AAAA,EAAE,MAAM,CAAC,CACjD,UAAW,EACX,SAAU,AAAA,EAAE,KAAK,CAAC,AAAA,EAAE,KAAK,CAAC,CAAC,AAAA,EAAE,MAAM,GAAI,AAAA,EAAE,KAAK,CAAC,AAAA,EAAE,MAAM,IAAI,GAC3D,QAAS,EACT,eAAgB,EAChB,cAAe,AAAA,EACb,QAAQ,GACR,OAAO,CACP,AAAA,EAAE,MAAM,CAAC,AAAC,GAAM,GAAK,AAAa,UAAb,OAAO,GAAkB,OAAO,aAAa,IAAI,EAAG,CACxE,QAAS,+BACV,IAEA,QAAQ,EACX,GD/La,EAAwB,AAAA,EAAE,MAAM,CAAC,CAC7C,SAAU,AAAA,EAAE,MAAM,GAClB,QAAS,AAAA,EAAE,MAAM,GAAG,EAAE,CAAC,AAAA,EAAE,IAAI,IAC7B,KAAM,AAAA,EAAE,MAAM,GAAG,EAAE,CAAC,AAAA,EAAE,IAAI,IAC1B,KAAM,AAAA,EAAE,MAAM,EACf,GAEa,EAA2B,AAAA,EAAE,MAAM,CAAC,CAChD,KAAM,AAAA,EAAE,MAAM,GACd,KAAM,AAAA,EAAE,MAAM,GAAG,MAAM,CAAC,AAAC,GAAM,GAAG,WAAW,MAAM,qBAAqB,QACxE,QAAS,AAAA,EAAE,GAAG,EACf,GEPO,SAAS,EAAe,CAAG,EACjC,IAAK,IAAM,KAAO,EACO,UAApB,OAAO,CAAG,CAAC,EAAI,EAClB,EAAe,CAAG,CAAC,EAAI,EAEZ,YAAR,IACC,EAAI,OAAU,CAAC,MAAM,EAExB,CAAA,EAAI,MAAS,CAAG,MAAM,IAAI,CAAC,IAAI,IAAI,EAAI,OAAU,EAAjD,EAED,OAAO,EAAI,OAAU,EAGvB,OAAO,CACR,CFLoC,EAAyB,MAAM,CAAC,CAEnE,gBAAiB,AAAA,EAAE,MAAM,EAC1B,GAE2C,AAAA,EAAE,MAAM,CAAC,CACnD,OAAQ,EACR,OAAQ,EACR,KAAM,AAAA,EAAE,MAAM,CAAC,CAAE,YAAa,2BAA4B,EAC3D,GAEqC,AAAA,EAAE,MAAM,CAAC,AAAA,EAAE,MAAM,CAAC,AAAA,EAAE,MAAM,GAAG,EAAE,CAAC,AAAA,EAAE,IAAI,MAEnC,AAAA,EAAE,MAAM,CAAC,CAChD,cAAe,AAAA,EAAE,MAAM,CAAC,AAAA,EAAE,KAAK,CAAC,AAAA,EAAE,MAAM,IACzC,GG1BO,IAAM,EAAmB,AAAC,GAChC,AAAI,MAAM,OAAO,CAAC,GACF,EAAE,GAAG,CAAC,GAEX,AAAa,UAAb,OAAO,EACV,KAAK,GACF,GAAK,EAAE,WAAW,GAAK,OAE1B,OAAO,WAAW,CACxB,OAAO,OAAO,CAAC,GAAG,GAAG,CAMpB,CAAC,CAAC,EAAG,EAAE,GAAK,CAAC,EAAG,EAAiB,GAAG,GAI/B,EASI,EAAmB,AAAC,GAChC,AAAI,MAAM,OAAO,CAAC,GACF,EAAE,GAAG,CAAC,GAEX,AAAa,UAAb,OAAO,EACV,KAAK,GACF,GAAK,EAAE,WAAW,GAAK,OAE1B,OAAO,WAAW,CACxB,OAAO,OAAO,CAAC,GAAG,GAAG,CAMpB,CAAC,CAAC,EAAG,EAAE,GAAK,CAAC,EAAG,EAAiB,GAAG,GAI/B,EJhCI,EAAgB,MAAO,IAEnC,IAAI,EAAM,AAAA,EAAK,OAAO,CAAC,MAEnB,EAAI,QAAQ,CAAC,cAAc,CAAA,EAAM,AAAA,EAAK,OAAO,CAAC,QAAlD,EAMA,IAAM,EAAa,AAHF,CAAA,MAAM,AAAA,EAAG,OAAO,CAAC,EAAK,CAAE,cAAe,CAAA,CAAK,EAAA,EAGjC,IAAI,CAAC,AAAC,GAAM,AAAW,YAAX,EAAE,IAAI,EAAkB,EAAE,WAAW,IAEvE,EAAgB,AAAA,EAAK,IAAI,CAAC,EAAK,WAGrC,GAAI,CAAC,EAAL,CACC,GAAI,CAAC,EAEJ,OADA,QAAQ,IAAI,CAAC,AAAA,EAAM,MAAM,CAAC,0BACnB,IAEP,OAAM,AAAA,EAAG,KAAK,CAAC,EAAe,CAAE,UAAW,CAAA,CAAK,GAChD,QAAQ,IAAI,CAAC,AAAA,EAAM,KAAK,CAAC,CAAC,+BAA+B,EAAE,EAAc,CAAC,E,CAK5E,OAAO,AAAA,EAAK,IAAI,CAAC,EAAK,UACvB,EAMa,EAAoB,AAAC,IAEjC,IAAM,EAAM,CAAC,EACP,EAAW,qCACjB,IAAK,GAAM,CAAC,EAAK,EAAM,GAAI,OAAO,OAAO,CAAC,QAAQ,GAAG,EAAG,CACvD,IAAM,EAAQ,EAAS,IAAI,CAAC,GAC5B,GAAI,CAAC,GACD,GAAO,OAAS,GAChB,CAAC,CAAK,CAAC,EAAE,CAAC,WAAW,GAAG,UAAU,CAAC,EAAW,WAAW,IAFjD,SAGZ,IAAM,EAAY,CAAK,CAAC,EAAE,CAAC,SAAS,CAAC,EAAW,MAAM,CAAG,GAAG,KAAK,CAAC,MAC9D,EAAI,EAER,EAAU,OAAO,CAAC,CAAC,EAAK,KACnB,EAAI,EAAU,MAAM,CAAG,GAErB,CAAC,CAAC,EAAI,EAAE,CAAA,CAAC,CAAC,EAAI,CAAG,CAAC,CAAA,EACvB,EAAI,CAAC,CAAC,EAAI,EAEV,CAAC,CAAC,EAAI,CAAG,CAEX,EACD,CACA,OAAO,CACR,EAOa,EAAa,MAAO,IAChC,IAAM,EAAqB,MAAM,AAAA,EAAG,OAAO,CAAC,GAE5C,OAAO,MAAM,QAAQ,GAAG,CACvB,EAAmB,GAAG,CAAC,MAAO,IAC7B,IAAM,EAAY,AAAA,EAAK,IAAI,CAAC,EAAY,GAExC,GAAI,CAAC,AADe,CAAA,MAAM,AAAA,EAAG,IAAI,CAAC,EAAlC,EACiB,WAAW,GAAI,MAAO,CAAA,EAEvC,IAAM,EAAa,MAAM,EAA4B,GACrD,GAAI,CAAC,EAAY,MAAO,CAAA,EAIxB,GAHK,EAAW,IAAI,EACnB,CAAA,EAAW,IAAI,CAA0B,EAAU,KAAK,CAAC,AAAA,EAAK,GAAG,EAAE,GAAG,EADvE,EAGI,CAAC,EAAW,IAAI,CACnB,MAAM,AAAI,MACT,CAAC,8FAA8F,EAAE,EAAU,CAAC,CAAC,EAQ/G,OALA,EAAW,OAAO,CAAG,AAAA,EAAM,EAAW,OAAO,CAAE,MAAM,EAAsB,IAE3E,EAAW,OAAO,CAAG,AAAA,EAAM,EAAW,OAAO,CAAE,EAAkB,EAAW,IAAI,GAGzE,CACN,GAAG,CAAU,CACb,gBAAiB,CAElB,CACD,IACC,IAAI,CAAC,AAAC,GAAyD,EAAE,MAAM,CAAC,SAC3E,EA6HA,eAAe,EAA4B,CAAS,MAc/C,EAbJ,IAAM,EAAgB,MAAM,AAAA,EAC1B,QAAQ,CAAC,AAAA,EAAK,IAAI,CAAC,EAAW,oBAC9B,IAAI,CAAC,AAAC,GAAM,EAAE,QAAQ,IACtB,KAAK,CAEL,AAAC,IACA,QAAQ,IAAI,CAAC,AAAA,EAAM,MAAM,CAAC,CAAC,IAAI,EAAE,EAAU,gCAAgC,CAAC,GAC5E,QAAQ,IAAI,CAAC,EAAE,OAAO,EACf,CAAA,IAGV,GAAI,AAAkB,CAAA,IAAlB,EAAyB,MAAO,CAAA,EAGpC,GAAI,CACH,EAAsB,AAAA,EAAK,KAAK,CAAC,EAClC,CAAE,MAAO,EAAG,CACX,MAAM,AAAI,MAAM,CAAC,oCAAoC,EAAE,EAAU,CAAC,CAAE,CAAE,MAAO,CAAE,EAChF,CAEA,IAAM,EAAmB,AAAA,EAAyB,SAAS,CAAC,GAC5D,GAAI,CAAC,EAAiB,OAAO,CAAE,CAC9B,QAAQ,KAAK,CAAC,AAAA,EAAM,IAAI,CAAC,GAAG,CAAC,CAAC,gCAAgC,EAAE,EAAU,CAAC,GAC3E,IAAM,EAAiB,AAAA,EAAe,EAAiB,KAAK,CAAC,MAAM,IACnE,QAAQ,KAAK,CAAC,AAAA,EAAM,GAAG,CAAC,2BACxB,IAAM,EAAU,AAAA,EAAM,GAAG,CAAC,IAI1B,OAHA,QAAQ,KAAK,CACZ,CAAC,EAAE,EAAQ,GAAG,EAAE,AAAA,EAAK,SAAS,CAAC,GAAgB,OAAO,CAAC,MAAO,CAAC;AAAE,EAAE,EAAQ,GAAG,CAAC,EAAE,CAAC,EAE7E,AAAI,MAAM,iCACjB,CACA,OAAO,EAAiB,IAAI,AAC7B,CAMA,eAAe,EAAsB,CAAS,EAC7C,IAAM,EAAkB,AAAA,EAAK,IAAI,CAAC,EAAW,2BAK7C,GAAI,CAJsB,MAAM,AAAA,EAC9B,IAAI,CAAC,GACL,IAAI,CAAC,IAAM,CAAA,GACX,KAAK,CAAC,IAAM,CAAA,GACU,MAAO,CAAC,EAChC,IAAM,EAAc,MAAM,AAAA,EAAG,QAAQ,CAAC,GAAiB,IAAI,CAAC,AAAC,GAAM,EAAE,QAAQ,IAC7E,GAAI,CACH,OAAO,AAAA,EAAiB,AAAA,EAAK,KAAK,CAAC,GACpC,CAAE,MAAO,EAAG,CACX,MAAM,AAAI,MAAM,CAAC,4CAA4C,EAAE,EAAU,CAAC,CAAE,CAAE,MAAO,CAAE,EACxF,CACD,CO5RA,IAAM,EAAiB,MAAO,GAEtB,AADgB,CAAA,MAAM,AAAA,EAAG,OAAO,CAAC,EAAxC,EACsB,QAAQ,CAAC,gBAUnB,EAAiB,MAAO,IAEpC,IAAM,EAAY,GAAiB,QAAQ,GAAG,GAIxC,EAAa,AAAA,EAAK,KAAK,CAAC,EAAU,KAAK,CAAC,gBAAgB,CAAC,EAAE,EAC7D,EAAI,CAAC,EAAE,EAAW,GAAG,CAAC,CAAC,EAAE,EAAW,IAAI,CAAC,CAAC,CACxC,EAAQ,EAId,IAFI,AADS,CAAA,MAAM,AAAA,EAAG,IAAI,CAAC,EAA3B,EACS,MAAM,IAAI,CAAA,EAAI,AAAA,EAAK,KAAK,CAAC,GAAG,GAAG,AAAH,EAE9B,CAAE,MAAM,EAAe,IAAK,CAClC,GAAI,IAAM,AAAA,EAAK,KAAK,CAAC,GAAG,IAAI,CAC3B,MAAM,AAAI,MAAM,CAAC,+BAA+B,EAAE,KAAK,SAAS,CAAC,CAAE,cAAA,EAAe,MAAA,CAAM,GAAG,CAAC,EAE7F,EAAI,AAAA,EAAK,KAAK,CAAC,GAAG,GAAG,AACtB,CAEA,OAAO,CACR,EGrCM,EAAsB,AAAA,EAAE,KAAK,CAAC,CACnC,AAAA,EAAE,MAAM,CAAC,CAAE,KAAM,AAAA,EAAE,MAAM,EAAG,EAAG,CAAE,YAAa,wCAAyC,GACvF,AAAA,EAAE,MAAM,CACP,CAAE,QAAS,AAAA,EAAE,MAAM,CAAC,CAAE,IAAK,AAAA,EAAE,MAAM,EAAG,EAAG,EACzC,CAAE,YAAa,2CAA4C,GAE5D,AAAA,EACE,MAAM,CAAC,CAAE,OAAQ,AAAA,EAAE,MAAM,EAAG,EAAG,CAAE,YAAa,0CAA2C,GACzF,QAAQ,GACV,EAEK,EAAoB,AAAA,EAAE,MAAM,CAAC,CAClC,KAAM,AAAA,EAAE,MAAM,GACd,SAAU,AAAA,EAAE,SAAS,EACtB,GAEa,EAAuB,AAAA,EAAE,YAAY,CAAC,EAAmB,GAEzD,EAAwB,AAAA,EAAE,YAAY,CAClD,EAAkB,MAAM,CAAC,CACxB,SAAU,AAAA,EAAE,MAAM,CAAC,CAClB,WAAY,AAAA,EAAE,OAAO,GAAG,QAAQ,GAChC,YAAa,AAAA,EAAE,KAAK,CAAC,AAAA,EAAE,KAAK,CAAC,CAAC,AAAA,EAAE,MAAM,GAAI,AAAA,EAAE,KAAK,CAAC,AAAA,EAAE,MAAM,IAAI,GAAG,QAAQ,GACzE,KAAM,AAAA,EAAE,MAAM,GAAG,QAAQ,EAC1B,EACD,GACA,GAGY,EAAqB,AAAA,EAAE,KAAK,CAAC,CAAC,EAAsB,EAAsB,EDpB1E,EAAiB,MAAO,IACpC,GAAI,CAEH,GAAI,CAAC,AADK,CAAA,MAAM,AAAA,EAAG,IAAI,CAAC,EAAxB,EACO,WAAW,GAAI,MAAO,CAAA,CAC9B,CAAE,MAAO,EAAG,CAkBX,OAjBI,aAAa,OAA8C,AAAY,WAAZ,EAAG,IAAI,CACrE,QAAQ,IAAI,CACX,AAAA,EAAM,MAAM,CACX,CAAC,mCAAmC,EAAE,AAAA,EAAM,IAAI,CAC/C,CAAC,CAAC,EAAE,EAAK,KAAK,CAAC,gBAAgB,CAAC,EAAE,CAAC,CAAC,CAAC,EACpC,EAAE,EAAE,EAAE,CAAC,CAAC,GAIZ,QAAQ,IAAI,CACX,AAAA,EAAM,MAAM,CACX,CAAC,IAAI,EAAE,AAAA,EAAM,IAAI,CAChB,CAAC,CAAC,EAAE,EAAK,KAAK,CAAC,gBAAgB,CAAC,EAAE,CAAC,CAAC,CAAC,EACpC,+FAA+F,CAAC,GAI9F,CAAA,CACR,CAGA,GAAI,CAAC,AADK,CAAA,MAAM,AAAA,EAAG,OAAO,CAAC,EAA3B,EACO,QAAQ,CAAC,gBAAiB,MAAO,CAAA,EAExC,IAAM,EAAiB,MAAM,AAAA,EAAG,QAAQ,CAAC,CAAC,EAAE,EAAK,aAAa,CAAC,EAAE,IAAI,CAEpE,AAAC,GAAgB,KAAK,KAAK,CAAC,EAAY,QAAQ,KAE3C,EAAY,AAAA,EAAmB,SAAS,CAAC,UAC/C,AAAI,EAAU,OAAO,CAAS,EAAU,IAAI,EAE3C,QAAQ,IAAI,CACX,AAAA,EAAM,MAAM,CACX,CAAC,IAAI,EAAE,AAAA,EAAM,IAAI,CAAC,CAAC,CAAC,EAAE,EAAK,KAAK,CAAC,gBAAgB,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,gCAAgC,CAAC,GAG5F,QAAQ,IAAI,CAAC,AAAA,EAAe,EAAU,KAAK,CAAC,MAAM,KAC3C,CAAA,EAET,EGpDa,EAAgC,AAAA,EAAE,MAAM,CAAC,CACrD,UAAW,AAAA,EAAE,KAAK,CAAC,AAAA,EAAE,MAAM,IAAI,OAAO,CAAC,EAAE,EACzC,QAAS,AAAA,EACP,MAAM,CACN,AAAA,EAAE,MAAM,CAAC,CAAE,YAAa,gBAAiB,GACzC,AAAA,EAAE,MAAM,CAAC,CAAE,YAAa,gBAAiB,IAEzC,OAAO,CAAC,CAAC,GAEX,SAAU,AAAA,EAAE,KAAK,CAAC,AAAA,EAAE,MAAM,IAAI,OAAO,CAAC,EAAE,CACzC,GAEa,EAAiC,AAAA,EAAE,MAAM,CAAC,CACtD,UAAW,AAAA,EAAE,KAAK,CAAC,AAAA,EAAE,MAAM,IAAI,OAAO,CAAC,EAAE,CAC1C,GAEa,EAAuB,AAAA,EAClC,MAAM,CAAC,CACP,WAAY,AAAA,EAAE,MAAM,CAAC,AAAA,EAAE,MAAM,GAAI,GACjC,YAAa,AAAA,EACX,MAAM,CAAC,AAAA,EAAE,MAAM,CAAC,CAAE,YAAa,qBAAsB,GAAI,GACzD,OAAO,CAAC,CAAC,EACZ,GACC,SAAS,GDfE,EAAa,AAAC,IAC1B,IAAM,EAAa,CAAC,EAAE,EAAQ,sBAAsB,CAAC,CACrD,GAAI,CACH,IAAM,EAAoB,AAAA,EAAG,YAAY,CAAC,EAAY,QAAQ,QAAQ,GAGhE,EAAY,AAAA,EAAK,KAAK,CAAC,EAAkB,UAAU,CAAC,gBAAiB,YAErE,EAAe,AAAA,EAAqB,SAAS,CAAC,GACpD,GAAI,CAAC,EAAa,OAAO,CAAE,CAC1B,QAAQ,KAAK,CACZ,AAAA,EAAM,IAAI,CAAC,GAAG,CACb,CAAC;qEAAyI,CAAC,GAG7I,IAAM,EAAiB,AAAA,EAAe,EAAa,KAAK,CAAC,MAAM,IAC/D,QAAQ,KAAK,CAAC,AAAA,EAAM,GAAG,CAAC,2BACxB,IAAM,EAAU,AAAA,EAAM,GAAG,CAAC,IAI1B,OAHA,QAAQ,KAAK,CACZ,CAAC,EAAE,EAAQ,GAAG,EAAE,AAAA,EAAK,SAAS,CAAC,GAAgB,OAAO,CAAC,MAAO,CAAC;AAAE,EAAE,EAAQ,GAAG,CAAC,EAAE,CAAC,EAE7E,AAAI,MAAM,gCACjB,CAEA,OAAO,EAAa,IAAI,AACzB,CAAE,MAAO,EAAG,CACX,GAAI,CAAE,CAAA,aAAa,KAAA,EAAQ,MAAM,EACjC,GAAI,EAAE,OAAO,CAAC,UAAU,CAAC,UACxB,MAAM,AAAI,MAAM,CAAC,+CAA+C,EAAE,EAAW,CAAC,CAAC,CAAE,CAChF,MAAO,CACR,EAED,OAAM,CACP,CACD,EHpCM,EACL,AAAC,GAMD,MAAO,IACN,IAAM,EAAc,AAAA,EAAK,OAAO,CAAC,EAAS,eAAgB,GACpD,EAAe,MAAM,AAAA,EAAe,SAC1C,EAAK,GACE,CACN,QAAS,EACT,KAAM,CACP,CACD,EAOY,EAA0B,MAAO,IAE7C,IAAM,EAAgB,AAAA,EAAW,GAgBjC,MAAO,CACN,WAdyB,MAAM,QAAQ,GAAG,CAC1C,OAAO,IAAI,CAAC,EAAc,UAAU,EAAE,GAAG,CAAC,EAAe,KACxD,IAAI,CAAC,AAAC,GAA+D,EAAK,MAAM,CAAC,UAalF,YAV0B,MAAM,QAAQ,GAAG,CAC3C,OAAO,IAAI,CAAC,EAAc,WAAW,EAAE,GAAG,CAAC,EAAe,KACzD,IAAI,CACL,AAAC,GAEC,EAAK,MAAM,CAAC,AAAC,GAAM,GAAK,CAAA,CAAQ,EAAE,OAAO,CAAC,QAAQ,EAAE,aAMvD,CACD,EF5CO,eAAe,EAAwB,CAAO,EAGpD,OAFK,GAAS,CAAA,EAAU,MAAM,AAAA,GAA9B,EAEO,MAAM,AAAA,EAAwB,EACtC,COAO,IAAM,EAAiB,MAAO,EAAa,EAAU,KAE3D,IAAM,EAAuB,IAAI,IAAI,CAAC,QAAQ,EAAE,EAAY,CAAC,EAAE,IAAI,CAC7D,EAAmB,MAAM,MAAM,CAAC,GAChC,EAAY,AAAA,EAA0B,SAAS,CAAC,CAAE,GAAG,CAAgB,CAAE,SAAA,CAAS,GAEtF,GAAK,EAAU,OAAO,CAUrB,OAAO,EAAU,IAAI,AAVE,EACvB,QAAQ,KAAK,CAAC,AAAA,EAAM,IAAI,CAAC,GAAG,CAAC,CAAC,0BAA0B,EAAE,EAAY,YAAY,CAAC,GACnF,IAAM,EAAiB,AAAA,EAAe,EAAU,KAAK,CAAC,MAAM,IAC5D,QAAQ,KAAK,CAAC,AAAA,EAAM,GAAG,CAAC,2BACxB,IAAM,EAAU,AAAA,EAAM,GAAG,CAAC,KAC1B,QAAQ,KAAK,CACZ,CAAC,EAAE,EAAQ,GAAG,EAAE,AAAA,EAAK,SAAS,CAAC,GAAgB,OAAO,CAAC,MAAO,CAAC;AAAE,EAAE,EAAQ,GAAG,CAAC,EAAE,CAAC,EAEnF,QAAQ,IAAI,CAAC,EACd,CAGD,ERrBO,eAAe,EAAqB,CAAG,CAAE,CAAW,EAC1D,IAAM,EAAoB,GAAgB,MAAM,AAAA,IAEhD,OAAO,MAAM,EAAkB,WAAW,CAAC,MAAM,CAQhD,MAAO,EAAM,KAIZ,IAAM,EAAM,MAAM,EAEZ,EAAU,MAAM,AAAA,EACrB,AAAA,EAAK,IAAI,CAAC,EAAE,IAAI,CAAE,EAAE,OAAO,CAAC,IAAI,EAChC,EAAE,OAAO,CAAC,QAAQ,EAAE,aAAe,EAAE,CACrC,EAAE,OAAO,CAAC,IAAI,EAuBf,OApBA,EAAE,OAAO,CAAC,QAAQ,CAAC,WAAW,EAAE,OAAO,QAAQ,AAAC,IAE/C,GAAI,KAAK,EAMR,MALA,QAAQ,KAAK,CACZ,AAAA,EAAM,GAAG,CACR,CAAC,6CAA6C,EAAE,EAAE,sCAAsC,CAAC,GAGrF,AAAI,MAAM,oCAGjB,CAAA,CAAG,CAAC,EAAE,CAAG,CACR,QAAS,EACT,QAAS,EAAQ,SAAS,CAC1B,QAAS,EAAQ,OAAO,CACxB,eAAgB,EAAQ,cAAc,CACtC,cAAkC,EAAQ,aAAa,AACxD,CACD,GAEO,CACR,EACA,QAAQ,OAAO,CAAC,CAAC,GAEnB,CNhDA,IAAM,EAAU,IAAI,EAEpB,EAAQ,IAAI,CAAC,0BACb,EAAQ,WAAW,CAAC,8CAEpB,EACE,OAAO,CAAC,gBACR,WAAW,CAAC,gCACZ,MAAM,CAAC,UACP,IAAM,EAAU,MAAM,AAAA,IAGtB,QAAQ,GAAG,CADI,MAAM,AAAA,EAAW,GAEjC,GACD,EACE,OAAO,CAAC,eACR,WAAW,CAAC,kCACZ,MAAM,CAAC,UACP,IAAM,EAAgB,MAAM,AAAA,IAC5B,GAAI,CAAC,EAAe,MAAM,AAAI,MAAM,6BAEpC,QAAQ,GAAG,CADS,MAAM,AAAA,EAAW,GAEtC,GACD,EACE,OAAO,CAAC,sBACR,WAAW,CAAC,6CACZ,MAAM,CAAC,UAEP,QAAQ,GAAG,CADK,MAAM,AAAA,IAEvB,GAED,EACE,OAAO,CAAC,oBACR,WAAW,CAAC,kDACZ,MAAM,CAAC,UAEP,QAAQ,GAAG,CADY,MAAM,AAAA,IAE9B,GAED,EAAQ,KAAK","sources":["<anon>","packages/plugin-connector/src/cli.js","packages/plugin-connector/src/data-sources/get-sources.js","packages/plugin-connector/src/data-sources/schemas/datasource-spec.schema.js","packages/plugin-connector/src/data-sources/schemas/query-runner.schema.js","packages/plugin-connector/src/lib/clean-zod-errors.js","packages/plugin-connector/src/lib/b64-deep.js","packages/plugin-connector/src/data-sources/get-datasource-plugins.js","packages/plugin-connector/src/plugin-discovery/index.js","packages/plugin-connector/src/plugin-discovery/get-root-modules.js","packages/plugin-connector/src/plugin-discovery/resolve-evidence-config.js","packages/plugin-connector/src/plugin-discovery/is-valid-package.js","packages/plugin-connector/src/plugin-discovery/schemas/evidence-package.schema.js","packages/plugin-connector/src/plugin-discovery/load-config.js","packages/plugin-connector/src/plugin-discovery/schemas/evidence-config.schema.js","packages/plugin-connector/src/data-sources/build-connector.js"],"sourcesContent":["import {Command as $kIqch$Command} from \"commander\";\nimport $kIqch$fspromises from \"fs/promises\";\nimport $kIqch$path from \"path\";\nimport $kIqch$yaml from \"yaml\";\nimport $kIqch$chalk from \"chalk\";\nimport $kIqch$lodashmerge from \"lodash.merge\";\nimport {createHash as $kIqch$createHash} from \"node:crypto\";\nimport {z as $kIqch$z} from \"zod\";\nimport $kIqch$fs from \"fs\";\n\n\n\n\n\n\n\n\n// Note that this only validates that the first item in the array\n// is a record with string keys. If the connector returns some\n// inconsistent array (e.g. [{}, 1]), it will not detect the\n// invalid row.\nconst $20af1336d074baeb$var$QueryResultArraySchema = (0, $kIqch$z).any().refine((data)=>{\n    // result is not an array, fail\n    if (!Array.isArray(data)) return false;\n    // result has no rows, we can't validate this\n    // but this is a correct result set\n    if (data.length === 0) return true;\n    return (0, $kIqch$z).record((0, $kIqch$z).string(), (0, $kIqch$z).any()).safeParse(data[0]).success;\n}, {\n    message: \"Data connector returned invalid rows\"\n});\nconst $20af1336d074baeb$var$QueryResultGeneratorSchema = (0, $kIqch$z).function();\nconst $20af1336d074baeb$export$c959e5da37fd983b = (0, $kIqch$z).object({\n    // Note that this only validates that the first item in the array\n    // is a record with string keys. If the connector returns some\n    // inconsistent array (e.g. [{}, 1]), it will not detect the\n    // invalid row.\n    rows: $20af1336d074baeb$var$QueryResultArraySchema.or($20af1336d074baeb$var$QueryResultGeneratorSchema),\n    columnTypes: (0, $kIqch$z).array((0, $kIqch$z).object({\n        name: (0, $kIqch$z).string(),\n        evidenceType: (0, $kIqch$z).enum([\n            \"boolean\",\n            \"number\",\n            \"string\",\n            \"date\"\n        ]),\n        typeFidelity: (0, $kIqch$z).union([\n            (0, $kIqch$z).literal(\"precise\"),\n            (0, $kIqch$z).literal(\"inferred\")\n        ])\n    })),\n    expectedRowCount: (0, $kIqch$z).number().optional()\n}).refine((data)=>{\n    // We can't dig into generator functions\n    if (typeof data.rows === \"function\") return true;\n    const rows = data.rows;\n    // Validate that all columnTypes appear\n    if (rows.length) {\n        // Filter to column types where name is not in row\n        // Then map columnTypes to their names to make things easier\n        // If there are any columns that were not filtered out; provide an error to zod\n        const missingColumns = data.columnTypes.filter((ct)=>!(ct.name in rows[0])).map((ct)=>ct.name);\n        if (missingColumns.length) return false;\n    }\n    return true;\n}, (data)=>{\n    // We can't dig into generator functions\n    if (typeof data.rows === \"function\") return {\n        path: [\n            \"columnTypes\"\n        ]\n    };\n    const rows = data.rows;\n    const missingColumns = data.columnTypes.filter((ct)=>!(ct.name in rows[0])).map((ct)=>ct.name);\n    return {\n        path: [\n            \"columnTypes\"\n        ],\n        message: `Datasource result has columns declared that are missing from results: ${missingColumns.join(\", \")}`\n    };\n}).refine((data)=>{\n    // We can't dig into generator functions\n    if (typeof data.rows === \"function\") return true;\n    // Validate that all columns in the returned rows have declared column types\n    if (data.rows.length) {\n        const colNames = data.columnTypes.map((ct)=>ct.name);\n        const extraColumns = Object.keys(data.rows[0]).filter((rowKey)=>!colNames.includes(rowKey));\n        if (extraColumns.length) return false;\n    }\n    return true;\n}, (data)=>{\n    // We can't dig into generator functions\n    if (typeof data.rows === \"function\") return {\n        path: [\n            \"rows\"\n        ]\n    };\n    const colNames = data.columnTypes.map((ct)=>ct.name);\n    const extraColumns = Object.keys(data.rows[0]).filter((rowKey)=>!colNames.includes(rowKey));\n    return {\n        path: [\n            \"rows\"\n        ],\n        message: `First row of results columns not provided in columnTypes: ${extraColumns.join(\", \")}`\n    };\n});\nconst $20af1336d074baeb$export$f5ddb356b686dd84 = (0, $kIqch$z).function().args((0, $kIqch$z).string({\n    description: \"QueryString\"\n}).or((0, $kIqch$z).null({\n    description: \"ExceededSizeQueryString\"\n})), (0, $kIqch$z).string({\n    description: \"QueryFilepath\"\n}), (0, $kIqch$z).number({\n    description: \"Batch Size\"\n}).or((0, $kIqch$z).null())).returns((0, $kIqch$z).promise($20af1336d074baeb$export$c959e5da37fd983b.or((0, $kIqch$z).null())).or($20af1336d074baeb$export$c959e5da37fd983b));\nconst $20af1336d074baeb$export$989ca211935133de = (0, $kIqch$z).function().args((0, $kIqch$z).any({\n    description: \"Connection Options\"\n})).returns((0, $kIqch$z).promise((0, $kIqch$z).union([\n    (0, $kIqch$z).literal(true),\n    (0, $kIqch$z).object({\n        reason: (0, $kIqch$z).string()\n    })\n])));\nconst $20af1336d074baeb$export$a0e9703f15a2290c = (0, $kIqch$z).function().args((0, $kIqch$z).any({\n    description: \"Connection Options\"\n}), (0, $kIqch$z).string({\n    description: \"Datasource directory\"\n})).returns((0, $kIqch$z).promise($20af1336d074baeb$export$f5ddb356b686dd84));\n/**\n * @typedef {Object} IDatasourceOptionSpecSchema\n * @property {string} title\n * @property {'string' | 'number' | 'boolean' | 'select' | 'file'} type\n * @property {boolean} [secret]\n * @property {boolean} [shown]\n * @property {string} [description]\n * @property {boolean} [virtual]\n * @property {boolean} [nest]\n * @property {string | number | boolean | undefined} [default]\n * @property {Record<string | number | symbol, Record<string, IDatasourceOptionSpecSchema>> | undefined} [children]\n */ const $20af1336d074baeb$var$primitive = (0, $kIqch$z).union([\n    (0, $kIqch$z).string(),\n    (0, $kIqch$z).number(),\n    (0, $kIqch$z).boolean()\n]);\nconst $20af1336d074baeb$export$7b12d43aed3b0368 = (0, $kIqch$z).record((0, $kIqch$z).string(), (0, $kIqch$z).object({\n    title: (0, $kIqch$z).string(),\n    type: (0, $kIqch$z).enum([\n        \"string\",\n        \"number\",\n        \"boolean\",\n        \"select\",\n        \"file\"\n    ]),\n    secret: (0, $kIqch$z).boolean().default(false),\n    shown: (0, $kIqch$z).boolean().optional(),\n    /**\n\t\t * Indicates that the field should not actually be persisted. Should be combined with `references`\n\t\t */ virtual: (0, $kIqch$z).boolean().default(false),\n    /**\n\t\t * Indicates that the field should get its value from another field if it is available\n\t\t */ references: (0, $kIqch$z).string().optional(),\n    /**\n\t\t * Indicates that the field can only get its value from the references\n\t\t */ forceReference: (0, $kIqch$z).boolean().default(false),\n    fileFormat: (0, $kIqch$z).enum([\n        \"json\",\n        \"yaml\"\n    ]).optional(),\n    description: (0, $kIqch$z).string().optional(),\n    children: (0, $kIqch$z).lazy(()=>(0, $kIqch$z).record((0, $kIqch$z).string(), $20af1336d074baeb$export$7b12d43aed3b0368)).optional(),\n    required: (0, $kIqch$z).boolean().default(false),\n    options: (0, $kIqch$z).union([\n        (0, $kIqch$z).string(),\n        (0, $kIqch$z).object({\n            value: $20af1336d074baeb$var$primitive,\n            label: (0, $kIqch$z).string()\n        })\n    ]).array().optional(),\n    nest: (0, $kIqch$z).boolean().optional(),\n    default: $20af1336d074baeb$var$primitive.optional()\n}));\nconst $20af1336d074baeb$export$4f0eb8607c96bd68 = (0, $kIqch$z).object({\n    getRunner: $20af1336d074baeb$export$a0e9703f15a2290c,\n    supports: (0, $kIqch$z).array((0, $kIqch$z).union([\n        (0, $kIqch$z).string(),\n        (0, $kIqch$z).array((0, $kIqch$z).string())\n    ])),\n    options: $20af1336d074baeb$export$7b12d43aed3b0368,\n    testConnection: $20af1336d074baeb$export$989ca211935133de,\n    processSource: (0, $kIqch$z).function().returns((0, $kIqch$z).custom((d)=>d && typeof d === \"object\" && Symbol.asyncIterator in d, {\n        message: \"Expected AsyncIterator result\"\n    })).optional()\n});\n\n\nconst $b1927a7a8d2c2fb9$export$89c81f16bad71a6b = (0, $kIqch$z).object({\n    filepath: (0, $kIqch$z).string(),\n    content: (0, $kIqch$z).string().or((0, $kIqch$z).null()),\n    hash: (0, $kIqch$z).string().or((0, $kIqch$z).null()),\n    name: (0, $kIqch$z).string()\n});\nconst $b1927a7a8d2c2fb9$export$e0cbf1bbd256fc2f = (0, $kIqch$z).object({\n    type: (0, $kIqch$z).string(),\n    name: (0, $kIqch$z).string().refine((s)=>s?.toString().match(/^[a-zA-Z0-9_-]+$/)?.length),\n    options: (0, $kIqch$z).any()\n});\nconst $b1927a7a8d2c2fb9$export$1c674577bd1f83c0 = $b1927a7a8d2c2fb9$export$e0cbf1bbd256fc2f.extend({\n    // queries: z.array(DatasourceQuerySchema),\n    sourceDirectory: (0, $kIqch$z).string()\n});\nconst $b1927a7a8d2c2fb9$export$1becbf11471723ce = (0, $kIqch$z).object({\n    source: $b1927a7a8d2c2fb9$export$89c81f16bad71a6b,\n    result: (0, $20af1336d074baeb$export$c959e5da37fd983b),\n    name: (0, $kIqch$z).string({\n        description: \"Output Table / Store name\"\n    })\n});\nconst $b1927a7a8d2c2fb9$export$b6d78fd3bc13e5ce = (0, $kIqch$z).record((0, $kIqch$z).record((0, $kIqch$z).string().or((0, $kIqch$z).null())));\nconst $b1927a7a8d2c2fb9$export$a1132735c513e70f = (0, $kIqch$z).object({\n    renderedFiles: (0, $kIqch$z).record((0, $kIqch$z).array((0, $kIqch$z).string()))\n});\n\n\n/**\n * Renames the '_errors' property to 'errors' in the given object and its nested objects recursively.\n * It also removes any empty errors arrays\n *\n * @param {any} obj - The object to rename the '_errors' property in.\n * @return {Object} The object with the renamed property.\n */ function $579fd89ba5cae013$export$71e7d3deffa0730b(obj) {\n    for(const key in obj){\n        if (typeof obj[key] === \"object\") $579fd89ba5cae013$export$71e7d3deffa0730b(obj[key]); // recursively traverse nested objects\n        if (key === \"_errors\") {\n            if (obj[\"_errors\"].length) // De-duplicate\n            obj[\"errors\"] = Array.from(new Set(obj[\"_errors\"]));\n            delete obj[\"_errors\"];\n        }\n    }\n    return obj;\n}\n\n\n\n/**\n * Encodes a value or an array of values into Base64 recursively.\n * @param {*} v - The value or array of values to encode.\n * @returns {*} - The encoded value or array of values.\n */ const $41db863454cd88ad$export$1867e32d63096a84 = (v)=>{\n    if (Array.isArray(v)) {\n        const mapped = v.map($41db863454cd88ad$export$1867e32d63096a84);\n        return mapped;\n    } else if (typeof v === \"string\") return btoa(v);\n    else if (v && v.constructor === Object) // bare object\n    return Object.fromEntries(Object.entries(v).map(/**\n\t\t\t\t * Maps each key-value pair of the object.\n\t\t\t\t * @param {[string, object]} entry - The key-value pair.\n\t\t\t\t * @returns {[string, object|string]} - The encoded key-value pair.\n\t\t\t\t */ ([k, v])=>[\n            k,\n            $41db863454cd88ad$export$1867e32d63096a84(v)\n        ]));\n    else return v;\n};\nconst $41db863454cd88ad$export$d5bf8907c6ddf98a = (v)=>{\n    if (Array.isArray(v)) {\n        const mapped = v.map($41db863454cd88ad$export$d5bf8907c6ddf98a);\n        return mapped;\n    } else if (typeof v === \"string\") return atob(v);\n    else if (v && v.constructor === Object) // bare object\n    return Object.fromEntries(Object.entries(v).map(/**\n\t\t\t\t * Maps each key-value pair of the object.\n\t\t\t\t * @param {[string, object]} entry - The key-value pair.\n\t\t\t\t * @returns {[string, object|string]} - The encoded key-value pair.\n\t\t\t\t */ ([k, v])=>[\n            k,\n            $41db863454cd88ad$export$d5bf8907c6ddf98a(v)\n        ]));\n    else return v;\n};\n\n\nconst $9fbfd3d9d29e05b1$export$46a3b0a4d36b05de = async (create)=>{\n    // Get the absolute path to the current working directory\n    let pwd = (0, $kIqch$path).resolve(\"./\");\n    if (pwd.includes(\".evidence\")) pwd = (0, $kIqch$path).resolve(\"../..\");\n    // Get the contents of the current directory\n    const contents = await (0, $kIqch$fspromises).readdir(pwd, {\n        withFileTypes: true\n    });\n    // Find the sources directory in the contents\n    const sourcesDir = contents.find((c)=>c.name === \"sources\" && c.isDirectory());\n    const sourceDirPath = (0, $kIqch$path).join(pwd, \"sources\");\n    // If sources directory doesn't exist, log a warning message\n    if (!sourcesDir) {\n        if (!create) {\n            console.warn((0, $kIqch$chalk).yellow(\"[!] No Sources Found!\"));\n            return null;\n        } else {\n            await (0, $kIqch$fspromises).mkdir(sourceDirPath, {\n                recursive: true\n            });\n            console.info((0, $kIqch$chalk).green(`Created new sources directory; ${sourceDirPath}`));\n        }\n    }\n    // Return the path to the sources directory\n    return (0, $kIqch$path).join(pwd, \"sources\");\n};\nconst $9fbfd3d9d29e05b1$export$4d546bd0a30a867d = (sourceName)=>{\n    /** @type {any} */ const out = {};\n    const keyRegex = /^EVIDENCE_SOURCE__([a-zA-Z0-1_]+)$/;\n    for (const [key, value] of Object.entries(process.env)){\n        const parts = keyRegex.exec(key);\n        if (!parts) continue;\n        if (parts?.length < 2) continue;\n        if (!parts[1].toLowerCase().startsWith(sourceName.toLowerCase())) continue;\n        const rawOptKey = parts[1].substring(sourceName.length + 2).split(\"__\");\n        let t = out;\n        rawOptKey.forEach((key, i)=>{\n            if (i < rawOptKey.length - 1) {\n                // We haven't reached the final key\n                if (!t[key]) t[key] = {};\n                t = t[key];\n            } else t[key] = value;\n        });\n    }\n    return out;\n};\nconst $9fbfd3d9d29e05b1$export$5f9bc633b116660f = async (sourcesDir)=>{\n    const sourcesDirectories = await (0, $kIqch$fspromises).readdir(sourcesDir);\n    /** @type {DatasourceSpec[]} */ return await Promise.all(sourcesDirectories.map(async (dirName)=>{\n        const sourceDir = (0, $kIqch$path).join(sourcesDir, dirName);\n        const possibleDir = await (0, $kIqch$fspromises).stat(sourceDir);\n        if (!possibleDir.isDirectory()) return false;\n        const connParams = await $9fbfd3d9d29e05b1$var$loadConnectionConfiguration(sourceDir);\n        if (!connParams) return false;\n        if (!connParams.name) connParams.name = /** @type {string} */ sourceDir.split((0, $kIqch$path).sep).pop();\n        if (!connParams.name) throw new Error(`Unexpected error determining datasource name, please add an explicit name in connection.yaml (${sourceDir})`);\n        // Load Options from connection.options.yaml\n        connParams.options = (0, $kIqch$lodashmerge)(connParams.options, await $9fbfd3d9d29e05b1$var$loadConnectionOptions(sourceDir));\n        // Load Options from Environment\n        connParams.options = (0, $kIqch$lodashmerge)(connParams.options, $9fbfd3d9d29e05b1$export$4d546bd0a30a867d(connParams.name));\n        // const queries = await getQueries(sourceDir, contents);\n        return {\n            ...connParams,\n            sourceDirectory: sourceDir\n        };\n    })).then((r)=>/** @type {Exclude<typeof r[number], false>[]} */ r.filter(Boolean));\n};\n/**\n *\n * @template {import(\"zod\").ZodType} T\n * @param {T} zod_schema\n * @param {string} file_path\n * @param {import(\"zod\").infer<T>} default_value\n * @param {string} error_message\n * @returns {Promise<import(\"zod\").infer<T>>}\n */ async function $9fbfd3d9d29e05b1$var$validateFile(zod_schema, file_path, default_value, error_message) {\n    const string_default = JSON.stringify(default_value);\n    const file_contents = await (0, $kIqch$fspromises).readFile(file_path, \"utf-8\").catch(()=>string_default);\n    const parsed = JSON.parse(file_contents);\n    const validated = zod_schema.safeParse(parsed);\n    if (!validated.success) {\n        console.error((0, $kIqch$chalk).bold.red(error_message));\n        await (0, $kIqch$fspromises).writeFile(file_path, string_default);\n        return default_value;\n    }\n    return validated.data;\n}\nasync function $9fbfd3d9d29e05b1$export$d113f6dd5d5b70e0(outDir) {\n    const manifestPath = (0, $kIqch$path).join(outDir, \"manifest.json\");\n    return $9fbfd3d9d29e05b1$var$validateFile((0, $b1927a7a8d2c2fb9$export$a1132735c513e70f), manifestPath, {\n        renderedFiles: {}\n    }, \"[!] Unable to parse manifest, ignoring\");\n}\nconst $9fbfd3d9d29e05b1$var$hash_location = \"sources/hashes.json\";\nasync function $9fbfd3d9d29e05b1$export$242ed7dd39449d16(baseDir) {\n    return $9fbfd3d9d29e05b1$var$validateFile((0, $b1927a7a8d2c2fb9$export$b6d78fd3bc13e5ce), (0, $kIqch$path).join(baseDir, $9fbfd3d9d29e05b1$var$hash_location), {}, \"[!] Unable to parse source query hashes, ignoring\");\n}\nasync function $9fbfd3d9d29e05b1$export$f2b0793804f52a8f(baseDir, hashes) {\n    const output = (0, $kIqch$path).join(baseDir, $9fbfd3d9d29e05b1$var$hash_location);\n    await (0, $kIqch$fspromises).mkdir((0, $kIqch$path).dirname(output), {\n        recursive: true\n    });\n    await (0, $kIqch$fspromises).writeFile(output, JSON.stringify(hashes));\n}\nasync function $9fbfd3d9d29e05b1$export$7854670c66555fc6(dataDir, hashes) {\n    const sourceDirectories = (await (0, $kIqch$fspromises).readdir(dataDir, {\n        withFileTypes: true\n    })).filter((r)=>r.isDirectory()).map((r)=>r.name);\n    const hashedSources = Object.keys(hashes);\n    for (const sourceName of sourceDirectories){\n        const sourcePath = (0, $kIqch$path).join(dataDir, sourceName);\n        // Clean up sources that have been renamed or removed\n        if (!hashedSources.includes(sourceName)) {\n            await (0, $kIqch$fspromises).rm(sourcePath, {\n                recursive: true,\n                force: true\n            });\n            continue;\n        }\n        const queries = await (0, $kIqch$fspromises).readdir(sourcePath);\n        const sourceHashes = hashes[sourceName];\n        for (const queryName of queries){\n            const queryPath = (0, $kIqch$path).join(sourcePath, queryName);\n            const currentResults = await (0, $kIqch$fspromises).readdir(queryPath);\n            for (const resultHash of currentResults)if (resultHash !== sourceHashes[queryName]) await (0, $kIqch$fspromises).rm((0, $kIqch$path).join(queryPath, resultHash), {\n                recursive: true,\n                force: true\n            });\n            if (!sourceHashes[queryName]) continue;\n            const queryHashPath = (0, $kIqch$path).join(queryPath, /** @type {string} */ sourceHashes[queryName]);\n            const timestamps = await (0, $kIqch$fspromises).readdir(queryHashPath);\n            const numbers = timestamps.map((x)=>Number(x)).filter((x)=>!isNaN(x));\n            if (!numbers.length) continue;\n            const latest = Math.max(...numbers).toString();\n            for (const timestamp of timestamps)if (timestamp !== latest) await (0, $kIqch$fspromises).rm((0, $kIqch$path).join(queryHashPath, timestamp), {\n                recursive: true,\n                force: true\n            });\n        }\n    }\n}\n/**\n * Reads a YAML file containing connection parameters from the given source directory,\n * parses it, and returns a validated datasource specification.\n *\n * @param {string} sourceDir - The directory containing the connection.yaml file.\n * @return {Promise<DatasourceSpecFile | false>} A Promise that resolves to a validated datasource specification, or false if the directory is not a source.\n */ async function $9fbfd3d9d29e05b1$var$loadConnectionConfiguration(sourceDir) {\n    const connParamsRaw = await (0, $kIqch$fspromises).readFile((0, $kIqch$path).join(sourceDir, \"connection.yaml\")).then((r)=>r.toString()).catch(/** @returns {false} */ (e)=>{\n        console.warn((0, $kIqch$chalk).yellow(`[!] ${sourceDir} is not a valid source; skipping`));\n        console.warn(e.message);\n        return false;\n    });\n    if (connParamsRaw === false) return false;\n    let connParamsUnchecked;\n    try {\n        connParamsUnchecked = (0, $kIqch$yaml).parse(connParamsRaw);\n    } catch (e) {\n        throw new Error(`Error parsing connection.yaml file; ${sourceDir}`, {\n            cause: e\n        });\n    }\n    const validationResult = (0, $b1927a7a8d2c2fb9$export$e0cbf1bbd256fc2f).safeParse(connParamsUnchecked);\n    if (!validationResult.success) {\n        console.error((0, $kIqch$chalk).bold.red(`[!] connection.yaml has errors (${sourceDir}`));\n        const formattedError = (0, $579fd89ba5cae013$export$71e7d3deffa0730b)(validationResult.error.format());\n        console.error((0, $kIqch$chalk).red(\"|   Discovered Errors:\"));\n        const redPipe = (0, $kIqch$chalk).red(\"|\");\n        console.error(`${redPipe}   ${(0, $kIqch$yaml).stringify(formattedError).replace(/\\n/g, `\\n${redPipe}   `)}`);\n        throw new Error(\"Unable to load connection.yaml\");\n    }\n    return validationResult.data;\n}\n/**\n * @returns {Promise<any>}\n * @param {string} sourceDir\n */ async function $9fbfd3d9d29e05b1$var$loadConnectionOptions(sourceDir) {\n    const optionsFilePath = (0, $kIqch$path).join(sourceDir, \"connection.options.yaml\");\n    const optionsFileExists = await (0, $kIqch$fspromises).stat(optionsFilePath).then(()=>true).catch(()=>false);\n    if (!optionsFileExists) return {};\n    const optionsFile = await (0, $kIqch$fspromises).readFile(optionsFilePath).then((r)=>r.toString());\n    try {\n        return (0, $41db863454cd88ad$export$d5bf8907c6ddf98a)((0, $kIqch$yaml).parse(optionsFile));\n    } catch (e) {\n        throw new Error(`Error parsing connection.options.yaml file; ${sourceDir}`, {\n            cause: e\n        });\n    }\n}\nasync function $9fbfd3d9d29e05b1$export$ecae802dba8a1831(sourceDir, contents) {\n    const queryFiles = await Promise.all(contents.filter((s)=>s !== \"connection.yaml\" && s !== \"connection.options.yaml\").flatMap(/**\n\t\t\t\t * @param {string} s\n\t\t\t\t * @returns {Promise<string[]>}\n\t\t\t\t */ async (s)=>{\n        /**\n\t\t\t\t\t * @param {string} dirPath\n\t\t\t\t\t * @returns {Promise<boolean>}\n\t\t\t\t\t */ async function isDir(dirPath) {\n            const stats = await (0, $kIqch$fspromises).lstat(dirPath);\n            return stats.isDirectory();\n        }\n        /**\n\t\t\t\t\t * @param {string} dirPath\n\t\t\t\t\t * @returns {Promise<string[]>}\n\t\t\t\t\t */ async function loadDirRecursive(dirPath) {\n            const content = await (0, $kIqch$fspromises).readdir(dirPath);\n            let output = [];\n            for (const filePath of content)if (await isDir((0, $kIqch$path).join(dirPath, filePath))) output.push(...await loadDirRecursive((0, $kIqch$path).join(dirPath, filePath)));\n            else output.push((0, $kIqch$path).join(dirPath, filePath));\n            return output;\n        }\n        const fullPath = (0, $kIqch$path).join(sourceDir, s);\n        if (await isDir(fullPath)) {\n            const recursed = await loadDirRecursive(fullPath);\n            return recursed.map((r)=>(0, $kIqch$path).relative(sourceDir, r));\n        } else return [\n            s\n        ];\n    })).then(/**\n\t\t * @param {string[][]} r\n\t\t * @returns {string[]}\n\t\t */ (r)=>r.flat(1));\n    const queries = await Promise.all(queryFiles.map(async (filename)=>{\n        const filepath = (0, $kIqch$path).join(sourceDir, filename);\n        const { size: size } = await (0, $kIqch$fspromises).stat(filepath);\n        let content, hash;\n        if (size > 104857600) {\n            console.warn(`${filename} is over 100MB, skipping`);\n            content = null;\n            hash = null;\n        } else {\n            content = await (0, $kIqch$fspromises).readFile((0, $kIqch$path).join(sourceDir, filename)).then((r)=>r.toString());\n            hash = (0, $kIqch$createHash)(\"md5\").update(content).digest(\"hex\");\n        }\n        return {\n            filepath: filepath,\n            content: content,\n            hash: hash,\n            name: (0, $kIqch$path).basename(filepath).split(\".\")[0]\n        };\n    }));\n    return queries;\n}\n\n\n\n\n/**\n * @param {string} p\n * @returns {Promise<boolean>}\n */ const $0d9f24ac34045674$var$hasNodeModules = async (p)=>{\n    const directoryItems = await (0, $kIqch$fspromises).readdir(p);\n    return directoryItems.includes(\"node_modules\");\n};\nconst $0d9f24ac34045674$export$6de9f17ef8a8b7d7 = async (startingPoint)=>{\n    // Either use the entry file or a specific startingPoint\n    const entryFile = startingPoint ?? process.cwd();\n    // Split the entryfile path on \"node_modules\", this will help if the main file is nested\n    // e.g. if sveltekit, main file will be node_modules/@sveltejs/kit/node_modules\n    // node_modules/.pnpm/vite@4.0.4/node_modules/vite/bin/vite.js\n    const parsedPath = (0, $kIqch$path).parse(entryFile.split(\"/node_modules\")[0]);\n    let p = `${parsedPath.dir}/${parsedPath.base}`;\n    const initP = p;\n    const stat = await (0, $kIqch$fspromises).stat(p);\n    if (stat.isFile()) p = (0, $kIqch$path).parse(p).dir;\n    while(!await $0d9f24ac34045674$var$hasNodeModules(p)){\n        if (p === (0, $kIqch$path).parse(p).root) throw new Error(`Could not locate node_modules! ${JSON.stringify({\n            startingPoint: startingPoint,\n            initP: initP\n        })}`);\n        p = (0, $kIqch$path).parse(p).dir;\n    }\n    return p;\n};\n\n\n\n\nconst $850532d8e21c1276$var$PackageExportSchema = (0, $kIqch$z).union([\n    (0, $kIqch$z).object({\n        main: (0, $kIqch$z).string()\n    }, {\n        description: \"Use the main field of the package.json\"\n    }),\n    (0, $kIqch$z).object({\n        exports: (0, $kIqch$z).object({\n            \".\": (0, $kIqch$z).string()\n        })\n    }, {\n        description: \"Use the exports field of the package.json\"\n    }),\n    (0, $kIqch$z).object({\n        svelte: (0, $kIqch$z).string()\n    }, {\n        description: \"Use the svelte field of the package.json\"\n    }).optional()\n]);\nconst $850532d8e21c1276$var$BasePackageSchema = (0, $kIqch$z).object({\n    name: (0, $kIqch$z).string(),\n    evidence: (0, $kIqch$z).undefined()\n});\nconst $850532d8e21c1276$export$a14d030d75ef573c = (0, $kIqch$z).intersection($850532d8e21c1276$var$BasePackageSchema, $850532d8e21c1276$var$PackageExportSchema);\nconst $850532d8e21c1276$export$bca9d2c38fe4cf42 = (0, $kIqch$z).intersection($850532d8e21c1276$var$BasePackageSchema.extend({\n    evidence: (0, $kIqch$z).object({\n        components: (0, $kIqch$z).boolean().optional(),\n        datasources: (0, $kIqch$z).array((0, $kIqch$z).union([\n            (0, $kIqch$z).string(),\n            (0, $kIqch$z).array((0, $kIqch$z).string())\n        ])).optional(),\n        icon: (0, $kIqch$z).string().optional()\n    })\n}), $850532d8e21c1276$var$PackageExportSchema);\nconst $850532d8e21c1276$export$ac6197b8a56da2df = (0, $kIqch$z).union([\n    $850532d8e21c1276$export$a14d030d75ef573c,\n    $850532d8e21c1276$export$bca9d2c38fe4cf42\n]);\n\n\n\n\nconst $ac2929749a5ac42a$export$f8dc70b6d32541e2 = async (path)=>{\n    try {\n        const s = await (0, $kIqch$fspromises).stat(path);\n        if (!s.isDirectory()) return false;\n    } catch (e) {\n        if (e instanceof Error && /** @type{NodeJS.ErrnoException} */ e.code !== \"ENOENT\") console.warn((0, $kIqch$chalk).yellow(`[!] An error occured while loading ${(0, $kIqch$chalk).bold(`\"${path.split(\"node_modules/\")[1]}\"`)}: ${e}.`));\n        else console.warn((0, $kIqch$chalk).yellow(`[!] ${(0, $kIqch$chalk).bold(`\"${path.split(\"node_modules/\")[1]}\"`)} could not be found in your node_modules. Check for spelling errors or try running npm install.`));\n        return false;\n    }\n    const c = await (0, $kIqch$fspromises).readdir(path);\n    if (!c.includes(\"package.json\")) return false;\n    const packageContent = await (0, $kIqch$fspromises).readFile(`${path}/package.json`).then(/** @param {Buffer} fileContent */ (fileContent)=>JSON.parse(fileContent.toString()));\n    const zodResult = (0, $850532d8e21c1276$export$ac6197b8a56da2df).safeParse(packageContent);\n    if (zodResult.success) return zodResult.data;\n    else {\n        console.warn((0, $kIqch$chalk).yellow(`[!] ${(0, $kIqch$chalk).bold(`\"${path.split(\"node_modules/\")[1]}\"`)} could not be loaded as a plugin`));\n        console.warn((0, $579fd89ba5cae013$export$71e7d3deffa0730b)(zodResult.error.format()));\n        return false;\n    }\n};\n\n\n\n\n\n\n\n\nconst $04d4158f42678bf5$export$797917169e2ec068 = (0, $kIqch$z).object({\n    overrides: (0, $kIqch$z).array((0, $kIqch$z).string()).default([]),\n    aliases: (0, $kIqch$z).record((0, $kIqch$z).string({\n        description: \"Component Name\"\n    }), (0, $kIqch$z).string({\n        description: \"Alias to apply\"\n    })).default({}),\n    provides: (0, $kIqch$z).array((0, $kIqch$z).string()).default([])\n});\nconst $04d4158f42678bf5$export$81ab33ffc20a47da = (0, $kIqch$z).object({\n    overrides: (0, $kIqch$z).array((0, $kIqch$z).string()).default([])\n});\nconst $04d4158f42678bf5$export$e691085fbd9bf5be = (0, $kIqch$z).object({\n    components: (0, $kIqch$z).record((0, $kIqch$z).string(), $04d4158f42678bf5$export$797917169e2ec068),\n    datasources: (0, $kIqch$z).record((0, $kIqch$z).string({\n        description: \"Plugin Package Name\"\n    }), $04d4158f42678bf5$export$81ab33ffc20a47da).default({})\n}).nonstrict();\n\n\nconst $682b92d065baf95f$export$c1a4367d4847eb06 = (rootDir)=>{\n    const configPath = `${rootDir}/evidence.plugins.yaml`;\n    try {\n        const configFileContent = (0, $kIqch$fs).readFileSync(configPath, \"utf8\").toString();\n        // Surround all YAML key that begin with \"@\" in quotes\n        // Skipping keys that are already quoted (e.g. beginning of line or whitespace)\n        const rawConfig = (0, $kIqch$yaml).parse(configFileContent.replaceAll(/($|\\s)(@.+):/g, '$1\"$2\":'));\n        const configResult = (0, $04d4158f42678bf5$export$e691085fbd9bf5be).safeParse(rawConfig);\n        if (!configResult.success) {\n            console.error((0, $kIqch$chalk).bold.red(`[!] evidence.plugins.yaml does not contain a valid configuration. \\n    Plugins will not be loaded. This may lead to unexpected behavior.`));\n            const formattedError = (0, $579fd89ba5cae013$export$71e7d3deffa0730b)(configResult.error.format());\n            console.error((0, $kIqch$chalk).red(\"|   Discovered Errors:\"));\n            const redPipe = (0, $kIqch$chalk).red(\"|\");\n            console.error(`${redPipe}   ${(0, $kIqch$yaml).stringify(formattedError).replace(/\\n/g, `\\n${redPipe}   `)}`);\n            throw new Error(\"Invalid evidence.plugins.yaml\");\n        }\n        return configResult.data;\n    } catch (e) {\n        if (!(e instanceof Error)) throw e;\n        if (e.message.startsWith(\"ENOENT\")) throw new Error(`Could not find evidence plugins file. (Look at ${configPath})`, {\n            cause: e\n        });\n        throw e;\n    }\n};\n\n\n/**\n * Wrapper function to create a package validator function\n * @param {string} rootDir\n * @returns {(packageName: string) => Promise<EvidencePluginPackage<ValidPackage> | false>}\n */ const $15f09b06c8f2a17d$var$validatePlugin = (rootDir)=>/**\n\t * Validates that the given package name exists and is a valid plugin package\n\t * @param {string} packageName\n\t * @returns {Promise<EvidencePluginPackage<ValidPackage> | false>}\n\t */ async (packageName)=>{\n        const packagePath = (0, $kIqch$path).resolve(rootDir, \"node_modules\", packageName);\n        const validPackage = await (0, $ac2929749a5ac42a$export$f8dc70b6d32541e2)(packagePath);\n        if (!validPackage) return false;\n        return {\n            package: validPackage,\n            path: packagePath\n        };\n    };\nconst $15f09b06c8f2a17d$export$4b0a2a49a61b15e5 = async (rootDir)=>{\n    /** @type {EvidenceConfig} */ const configContent = (0, $682b92d065baf95f$export$c1a4367d4847eb06)(rootDir);\n    /** @type {EvidencePluginPackage<ValidPackage>[]} */ const componentPackages = await Promise.all(Object.keys(configContent.components).map($15f09b06c8f2a17d$var$validatePlugin(rootDir))).then((pack)=>/** @type {Exclude<typeof pack[number], false>[]} */ pack.filter(Boolean));\n    /** @type {EvidencePluginPackage<EvidenceDatasourcePackage>[]} */ const datasourcePackages = await Promise.all(Object.keys(configContent.datasources).map($15f09b06c8f2a17d$var$validatePlugin(rootDir))).then((pack)=>/** @type {EvidencePluginPackage<EvidenceDatasourcePackage>[]} */ pack.filter((p)=>p && Boolean(p.package.evidence?.datasources)));\n    return {\n        components: componentPackages,\n        datasources: datasourcePackages\n    };\n};\n\n\nasync function $4772adaeeb479286$export$9418d811d68624a6(rootDir) {\n    if (!rootDir) rootDir = await (0, $0d9f24ac34045674$export$6de9f17ef8a8b7d7)();\n    return await (0, $15f09b06c8f2a17d$export$4b0a2a49a61b15e5)(rootDir);\n}\n\n\n\n\n\n\nconst $200a5e7a6f294d86$export$ebbe0f536b18196e = async (packageMain, supports, packageName)=>{\n    // https://github.com/nodejs/node/issues/31710 thanks windows\n    const crossPlatformPackage = new URL(`file:///${packageMain}`).href;\n    const connectorPackage = await import(crossPlatformPackage /* @vite-ignore */ );\n    const connector = (0, $20af1336d074baeb$export$4f0eb8607c96bd68).safeParse({\n        ...connectorPackage,\n        supports: supports\n    });\n    if (!connector.success) {\n        console.error((0, $kIqch$chalk).bold.red(`[!] Datasource connector \"${packageName}\" is invalid`));\n        const formattedError = (0, $579fd89ba5cae013$export$71e7d3deffa0730b)(connector.error.format());\n        console.error((0, $kIqch$chalk).red(\"|   Discovered Errors:\"));\n        const redPipe = (0, $kIqch$chalk).red(\"|\");\n        console.error(`${redPipe}   ${(0, $kIqch$yaml).stringify(formattedError).replace(/\\n/g, `\\n${redPipe}   `)}`);\n        process.exit(1);\n    } else return connector.data;\n};\n\n\n\n\nasync function $f24b7cd857e13d65$export$8fbb278aab496aa6(cfg, discoveries) {\n    const pluginDiscoveries = discoveries ?? await (0, $4772adaeeb479286$export$9418d811d68624a6)();\n    return await pluginDiscoveries.datasources.reduce(/**\n\t\t * Adds a plugin to a map of EvidencePluginPackages with a corresponding DatasourceConnectorFactory,\n\t\t * ensuring that no duplicate datasources are added.\n\t\t * @param {Promise<Record<string, PluginDatasources[string]>>} _acc - A promise representing the current state of the package map\n\t\t * @param {EvidencePluginPackage<EvidenceDatasourcePackage>} v - The plugin package to be added to the map\n\t\t * @returns {Promise<Record<string, PluginDatasources[string]>>} - A promise representing the updated package map\n\t\t */ async (_acc, v)=>{\n        // TODO: Handle Overrides\n        // Wait for the current state of the package map to resolve\n        const acc = await _acc;\n        // Build a DatasourceConnectorFactory for the plugin package's datasourcess\n        const factory = await (0, $200a5e7a6f294d86$export$ebbe0f536b18196e)((0, $kIqch$path).join(v.path, v.package.main), v.package.evidence?.datasources ?? [], v.package.name);\n        // For each datasource in the plugin package...\n        v.package.evidence.datasources?.flat().forEach((d)=>{\n            // If a plugin with the same datasource already exists in the map, throw an error\n            if (d in acc) {\n                console.error((0, $kIqch$chalk).red(`[!] Multiple datasource connectors found for ${d}. Please ensure that only one is used.`));\n                throw new Error(\"Datasource plugin conflict found!\");\n            }\n            // Otherwise, add the plugin package and its DatasourceConnectorFactory to the map\n            acc[d] = {\n                package: v,\n                factory: factory.getRunner,\n                options: factory.options,\n                testConnection: factory.testConnection,\n                processSource: /** @type {*} **/ factory.processSource // We can't really validate AsyncIterator output\n            };\n        });\n        // Return the updated package map as a promise\n        return acc;\n    }, Promise.resolve({}));\n}\n\n\n\n\n\n// import { execSource } from './data-sources/exec-source';\nconst $444c6539df4427ec$var$program = new (0, $kIqch$Command)();\n$444c6539df4427ec$var$program.name(\"plugin-connector-debug\");\n$444c6539df4427ec$var$program.description(\"CLI to debug the evidence plugin connector\");\n$444c6539df4427ec$var$program.command(\"print-config\").description(\"Print a parsed configuration\").action(async ()=>{\n    const rootDir = await (0, $0d9f24ac34045674$export$6de9f17ef8a8b7d7)();\n    const config = await (0, $682b92d065baf95f$export$c1a4367d4847eb06)(rootDir);\n    console.log(config);\n});\n$444c6539df4427ec$var$program.command(\"get-sources\").description(\"Print a parsed list of sources\").action(async ()=>{\n    const datasourceDir = await (0, $9fbfd3d9d29e05b1$export$46a3b0a4d36b05de)();\n    if (!datasourceDir) throw new Error(\"missing sources directory\");\n    const datasources = await (0, $9fbfd3d9d29e05b1$export$5f9bc633b116660f)(datasourceDir);\n    console.log(datasources);\n});\n$444c6539df4427ec$var$program.command(\"get-source-plugins\").description(\"Print a parsed list of datasource plugins\").action(async ()=>{\n    const plugins = await (0, $f24b7cd857e13d65$export$8fbb278aab496aa6)();\n    console.log(plugins);\n});\n$444c6539df4427ec$var$program.command(\"root-modules-dir\").description(\"Print the detected node_modules directory path\").action(async ()=>{\n    const rootModulesDir = await (0, $0d9f24ac34045674$export$6de9f17ef8a8b7d7)();\n    console.log(rootModulesDir);\n});\n$444c6539df4427ec$var$program.parse();\n\n\n//# sourceMappingURL=cli.js.map\n","import { getSources, getSourcesDir } from './data-sources/get-sources';\nimport { getDatasourcePlugins } from './data-sources/get-datasource-plugins';\nimport { getRootModules } from './plugin-discovery/get-root-modules';\n\nimport { Command } from 'commander';\nimport { loadConfig } from './plugin-discovery/load-config';\n// import { execSource } from './data-sources/exec-source';\n\nconst program = new Command();\n\nprogram.name('plugin-connector-debug');\nprogram.description('CLI to debug the evidence plugin connector');\n\nprogram\n\t.command('print-config')\n\t.description('Print a parsed configuration')\n\t.action(async () => {\n\t\tconst rootDir = await getRootModules();\n\n\t\tconst config = await loadConfig(rootDir);\n\t\tconsole.log(config);\n\t});\nprogram\n\t.command('get-sources')\n\t.description('Print a parsed list of sources')\n\t.action(async () => {\n\t\tconst datasourceDir = await getSourcesDir();\n\t\tif (!datasourceDir) throw new Error('missing sources directory');\n\t\tconst datasources = await getSources(datasourceDir);\n\t\tconsole.log(datasources);\n\t});\nprogram\n\t.command('get-source-plugins')\n\t.description('Print a parsed list of datasource plugins')\n\t.action(async () => {\n\t\tconst plugins = await getDatasourcePlugins();\n\t\tconsole.log(plugins);\n\t});\n\nprogram\n\t.command('root-modules-dir')\n\t.description('Print the detected node_modules directory path')\n\t.action(async () => {\n\t\tconst rootModulesDir = await getRootModules();\n\t\tconsole.log(rootModulesDir);\n\t});\n\nprogram.parse();\n","import fs from 'fs/promises';\nimport path from 'path';\nimport yaml from 'yaml';\nimport chalk from 'chalk';\nimport merge from 'lodash.merge';\nimport {\n\tDatasourceSpecFileSchema,\n\tDatasourceCacheSchema,\n\tDatasourceManifestSchema\n} from './schemas/datasource-spec.schema';\nimport { cleanZodErrors } from '../lib/clean-zod-errors.js';\nimport { createHash } from 'node:crypto';\nimport { decodeBase64Deep } from '../lib/b64-deep';\n\n/**\n * Returns the path to the sources directory, if it exists in the current directory.\n * If it doesn't exist, it logs a warning message and returns null.\n * @param {boolean} [create] indicates that the directory should be created if it does not exist\n * @returns {Promise<string|null>} The path to the sources directory or null.\n */\nexport const getSourcesDir = async (create) => {\n\t// Get the absolute path to the current working directory\n\tlet pwd = path.resolve('./');\n\n\tif (pwd.includes('.evidence')) pwd = path.resolve('../..');\n\n\t// Get the contents of the current directory\n\tconst contents = await fs.readdir(pwd, { withFileTypes: true });\n\n\t// Find the sources directory in the contents\n\tconst sourcesDir = contents.find((c) => c.name === 'sources' && c.isDirectory());\n\n\tconst sourceDirPath = path.join(pwd, 'sources');\n\n\t// If sources directory doesn't exist, log a warning message\n\tif (!sourcesDir) {\n\t\tif (!create) {\n\t\t\tconsole.warn(chalk.yellow('[!] No Sources Found!'));\n\t\t\treturn null;\n\t\t} else {\n\t\t\tawait fs.mkdir(sourceDirPath, { recursive: true });\n\t\t\tconsole.info(chalk.green(`Created new sources directory; ${sourceDirPath}`));\n\t\t}\n\t}\n\n\t// Return the path to the sources directory\n\treturn path.join(pwd, 'sources');\n};\n\n/**\n * @param {string} sourceName\n * @returns {any}\n */\nexport const loadSourceOptions = (sourceName) => {\n\t/** @type {any} */\n\tconst out = {};\n\tconst keyRegex = /^EVIDENCE_SOURCE__([a-zA-Z0-1_]+)$/;\n\tfor (const [key, value] of Object.entries(process.env)) {\n\t\tconst parts = keyRegex.exec(key);\n\t\tif (!parts) continue;\n\t\tif (parts?.length < 2) continue;\n\t\tif (!parts[1].toLowerCase().startsWith(sourceName.toLowerCase())) continue;\n\t\tconst rawOptKey = parts[1].substring(sourceName.length + 2).split('__');\n\t\tlet t = out;\n\n\t\trawOptKey.forEach((key, i) => {\n\t\t\tif (i < rawOptKey.length - 1) {\n\t\t\t\t// We haven't reached the final key\n\t\t\t\tif (!t[key]) t[key] = {};\n\t\t\t\tt = t[key];\n\t\t\t} else {\n\t\t\t\tt[key] = value;\n\t\t\t}\n\t\t});\n\t}\n\treturn out;\n};\n\n/**\n * Get a list of all sources and their connection info\n * @param {string} sourcesDir The path to the sources directory\n * @returns {Promise<DatasourceSpec[]>} An array of DatasourceSpecs\n */\nexport const getSources = async (sourcesDir) => {\n\tconst sourcesDirectories = await fs.readdir(sourcesDir);\n\t/** @type {DatasourceSpec[]} */\n\treturn await Promise.all(\n\t\tsourcesDirectories.map(async (dirName) => {\n\t\t\tconst sourceDir = path.join(sourcesDir, dirName);\n\t\t\tconst possibleDir = await fs.stat(sourceDir);\n\t\t\tif (!possibleDir.isDirectory()) return false;\n\n\t\t\tconst connParams = await loadConnectionConfiguration(sourceDir);\n\t\t\tif (!connParams) return false;\n\t\t\tif (!connParams.name)\n\t\t\t\tconnParams.name = /** @type {string} */ (sourceDir.split(path.sep).pop());\n\n\t\t\tif (!connParams.name)\n\t\t\t\tthrow new Error(\n\t\t\t\t\t`Unexpected error determining datasource name, please add an explicit name in connection.yaml (${sourceDir})`\n\t\t\t\t);\n\t\t\t// Load Options from connection.options.yaml\n\t\t\tconnParams.options = merge(connParams.options, await loadConnectionOptions(sourceDir));\n\t\t\t// Load Options from Environment\n\t\t\tconnParams.options = merge(connParams.options, loadSourceOptions(connParams.name));\n\n\t\t\t// const queries = await getQueries(sourceDir, contents);\n\t\t\treturn {\n\t\t\t\t...connParams,\n\t\t\t\tsourceDirectory: sourceDir\n\t\t\t\t// queries: queries\n\t\t\t};\n\t\t})\n\t).then((r) => /** @type {Exclude<typeof r[number], false>[]} */ (r.filter(Boolean)));\n};\n\n/**\n *\n * @template {import(\"zod\").ZodType} T\n * @param {T} zod_schema\n * @param {string} file_path\n * @param {import(\"zod\").infer<T>} default_value\n * @param {string} error_message\n * @returns {Promise<import(\"zod\").infer<T>>}\n */\nasync function validateFile(zod_schema, file_path, default_value, error_message) {\n\tconst string_default = JSON.stringify(default_value);\n\n\tconst file_contents = await fs.readFile(file_path, 'utf-8').catch(() => string_default);\n\tconst parsed = JSON.parse(file_contents);\n\tconst validated = zod_schema.safeParse(parsed);\n\n\tif (!validated.success) {\n\t\tconsole.error(chalk.bold.red(error_message));\n\t\tawait fs.writeFile(file_path, string_default);\n\t\treturn default_value;\n\t}\n\n\treturn validated.data;\n}\n\n/**\n *\n * @param {string} outDir\n * @returns {Promise<import(\"zod\").infer<typeof DatasourceManifestSchema>>}\n */\nexport async function getCurrentManifest(outDir) {\n\tconst manifestPath = path.join(outDir, 'manifest.json');\n\treturn validateFile(\n\t\tDatasourceManifestSchema,\n\t\tmanifestPath,\n\t\t{ renderedFiles: {} },\n\t\t'[!] Unable to parse manifest, ignoring'\n\t);\n}\n\nconst hash_location = 'sources/hashes.json';\n\n/**\n * Gets the hashes of all source files, at the time of their last execution.\n * @param {string} baseDir The path to .evidence/template\n * @returns {Promise<import(\"zod\").infer<typeof DatasourceCacheSchema>>}\n */\nexport async function getPastSourceHashes(baseDir) {\n\treturn validateFile(\n\t\tDatasourceCacheSchema,\n\t\tpath.join(baseDir, hash_location),\n\t\t{},\n\t\t'[!] Unable to parse source query hashes, ignoring'\n\t);\n}\n\n/**\n * Saves the supplied source hashes\n * @param {string} baseDir The path to .evidence/template\n * @param {import(\"zod\").infer<typeof DatasourceCacheSchema>} hashes\n */\nexport async function saveSourceHashes(baseDir, hashes) {\n\tconst output = path.join(baseDir, hash_location);\n\tawait fs.mkdir(path.dirname(output), { recursive: true });\n\tawait fs.writeFile(output, JSON.stringify(hashes));\n}\n\n/**\n * Saves the supplied source hashes\n * @param {string} dataDir The path to .evidence/template\n * @param {import(\"zod\").infer<typeof DatasourceCacheSchema>} hashes\n */\nexport async function cleanParquetFiles(dataDir, hashes) {\n\tconst sourceDirectories = (await fs.readdir(dataDir, { withFileTypes: true }))\n\t\t.filter((r) => r.isDirectory())\n\t\t.map((r) => r.name);\n\tconst hashedSources = Object.keys(hashes);\n\n\tfor (const sourceName of sourceDirectories) {\n\t\tconst sourcePath = path.join(dataDir, sourceName);\n\t\t// Clean up sources that have been renamed or removed\n\t\tif (!hashedSources.includes(sourceName)) {\n\t\t\tawait fs.rm(sourcePath, { recursive: true, force: true });\n\t\t\tcontinue;\n\t\t}\n\n\t\tconst queries = await fs.readdir(sourcePath);\n\t\tconst sourceHashes = hashes[sourceName];\n\t\tfor (const queryName of queries) {\n\t\t\tconst queryPath = path.join(sourcePath, queryName);\n\t\t\tconst currentResults = await fs.readdir(queryPath);\n\t\t\tfor (const resultHash of currentResults) {\n\t\t\t\tif (resultHash !== sourceHashes[queryName]) {\n\t\t\t\t\tawait fs.rm(path.join(queryPath, resultHash), { recursive: true, force: true });\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (!sourceHashes[queryName]) continue;\n\t\t\tconst queryHashPath = path.join(queryPath, /** @type {string} */ (sourceHashes[queryName]));\n\t\t\tconst timestamps = await fs.readdir(queryHashPath);\n\t\t\tconst numbers = timestamps.map((x) => Number(x)).filter((x) => !isNaN(x));\n\n\t\t\tif (!numbers.length) continue;\n\t\t\tconst latest = Math.max(...numbers).toString();\n\t\t\tfor (const timestamp of timestamps) {\n\t\t\t\tif (timestamp !== latest) {\n\t\t\t\t\tawait fs.rm(path.join(queryHashPath, timestamp), {\n\t\t\t\t\t\trecursive: true,\n\t\t\t\t\t\tforce: true\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n\n/**\n * Reads a YAML file containing connection parameters from the given source directory,\n * parses it, and returns a validated datasource specification.\n *\n * @param {string} sourceDir - The directory containing the connection.yaml file.\n * @return {Promise<DatasourceSpecFile | false>} A Promise that resolves to a validated datasource specification, or false if the directory is not a source.\n */\nasync function loadConnectionConfiguration(sourceDir) {\n\tconst connParamsRaw = await fs\n\t\t.readFile(path.join(sourceDir, 'connection.yaml'))\n\t\t.then((r) => r.toString())\n\t\t.catch(\n\t\t\t/** @returns {false} */\n\t\t\t(e) => {\n\t\t\t\tconsole.warn(chalk.yellow(`[!] ${sourceDir} is not a valid source; skipping`));\n\t\t\t\tconsole.warn(e.message);\n\t\t\t\treturn false;\n\t\t\t}\n\t\t);\n\tif (connParamsRaw === false) return false;\n\n\tlet connParamsUnchecked;\n\ttry {\n\t\tconnParamsUnchecked = yaml.parse(connParamsRaw);\n\t} catch (e) {\n\t\tthrow new Error(`Error parsing connection.yaml file; ${sourceDir}`, { cause: e });\n\t}\n\n\tconst validationResult = DatasourceSpecFileSchema.safeParse(connParamsUnchecked);\n\tif (!validationResult.success) {\n\t\tconsole.error(chalk.bold.red(`[!] connection.yaml has errors (${sourceDir}`));\n\t\tconst formattedError = cleanZodErrors(validationResult.error.format());\n\t\tconsole.error(chalk.red('|   Discovered Errors:'));\n\t\tconst redPipe = chalk.red('|');\n\t\tconsole.error(\n\t\t\t`${redPipe}   ${yaml.stringify(formattedError).replace(/\\n/g, `\\n${redPipe}   `)}`\n\t\t);\n\t\tthrow new Error('Unable to load connection.yaml');\n\t}\n\treturn validationResult.data;\n}\n\n/**\n * @returns {Promise<any>}\n * @param {string} sourceDir\n */\nasync function loadConnectionOptions(sourceDir) {\n\tconst optionsFilePath = path.join(sourceDir, 'connection.options.yaml');\n\tconst optionsFileExists = await fs\n\t\t.stat(optionsFilePath)\n\t\t.then(() => true)\n\t\t.catch(() => false);\n\tif (!optionsFileExists) return {};\n\tconst optionsFile = await fs.readFile(optionsFilePath).then((r) => r.toString());\n\ttry {\n\t\treturn decodeBase64Deep(yaml.parse(optionsFile));\n\t} catch (e) {\n\t\tthrow new Error(`Error parsing connection.options.yaml file; ${sourceDir}`, { cause: e });\n\t}\n}\n\n/**\n * Retrieves the contents of all query files in the source directory,\n * excluding the 'connection.yaml' file, and returns them as an array of\n * objects containing the filepath and content of each query file.\n *\n * @param {string} sourceDir - The path to the source directory.\n * @param {Array<string>} contents - An array of filenames in the source directory.\n * @return {Promise<DatasourceQuery[]>} - A promise that resolves to an array of objects\n * containing the filepath and content of each query file.\n */\nexport async function getQueries(sourceDir, contents) {\n\tconst queryFiles = await Promise.all(\n\t\tcontents\n\t\t\t.filter((s) => s !== 'connection.yaml' && s !== 'connection.options.yaml')\n\t\t\t.flatMap(\n\t\t\t\t/**\n\t\t\t\t * @param {string} s\n\t\t\t\t * @returns {Promise<string[]>}\n\t\t\t\t */\n\n\t\t\t\tasync (s) => {\n\t\t\t\t\t/**\n\t\t\t\t\t * @param {string} dirPath\n\t\t\t\t\t * @returns {Promise<boolean>}\n\t\t\t\t\t */\n\t\t\t\t\tasync function isDir(dirPath) {\n\t\t\t\t\t\tconst stats = await fs.lstat(dirPath);\n\t\t\t\t\t\treturn stats.isDirectory();\n\t\t\t\t\t}\n\n\t\t\t\t\t/**\n\t\t\t\t\t * @param {string} dirPath\n\t\t\t\t\t * @returns {Promise<string[]>}\n\t\t\t\t\t */\n\t\t\t\t\tasync function loadDirRecursive(dirPath) {\n\t\t\t\t\t\tconst content = await fs.readdir(dirPath);\n\t\t\t\t\t\tlet output = [];\n\t\t\t\t\t\tfor (const filePath of content) {\n\t\t\t\t\t\t\tif (await isDir(path.join(dirPath, filePath))) {\n\t\t\t\t\t\t\t\toutput.push(...(await loadDirRecursive(path.join(dirPath, filePath))));\n\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\toutput.push(path.join(dirPath, filePath));\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn output;\n\t\t\t\t\t}\n\n\t\t\t\t\tconst fullPath = path.join(sourceDir, s);\n\t\t\t\t\tif (await isDir(fullPath)) {\n\t\t\t\t\t\tconst recursed = await loadDirRecursive(fullPath);\n\t\t\t\t\t\treturn recursed.map((r) => path.relative(sourceDir, r));\n\t\t\t\t\t} else {\n\t\t\t\t\t\treturn [s];\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t)\n\t).then(\n\t\t/**\n\t\t * @param {string[][]} r\n\t\t * @returns {string[]}\n\t\t */\n\t\t(r) => r.flat(1)\n\t);\n\n\tconst queries = await Promise.all(\n\t\tqueryFiles.map(async (filename) => {\n\t\t\tconst filepath = path.join(sourceDir, filename);\n\t\t\tconst { size } = await fs.stat(filepath);\n\t\t\tlet content, hash;\n\t\t\tif (size > 100 * 1024 * 1024) {\n\t\t\t\tconsole.warn(`${filename} is over 100MB, skipping`);\n\t\t\t\tcontent = null;\n\t\t\t\thash = null;\n\t\t\t} else {\n\t\t\t\tcontent = await fs.readFile(path.join(sourceDir, filename)).then((r) => r.toString());\n\t\t\t\thash = createHash('md5').update(content).digest('hex');\n\t\t\t}\n\n\t\t\treturn { filepath, content, hash, name: path.basename(filepath).split('.')[0] };\n\t\t})\n\t);\n\n\treturn queries;\n}\n","import { z } from 'zod';\nimport { QueryResultSchema } from './query-runner.schema';\n\nexport const DatasourceQuerySchema = z.object({\n\tfilepath: z.string(),\n\tcontent: z.string().or(z.null()),\n\thash: z.string().or(z.null()),\n\tname: z.string()\n});\n\nexport const DatasourceSpecFileSchema = z.object({\n\ttype: z.string(),\n\tname: z.string().refine((s) => s?.toString().match(/^[a-zA-Z0-9_-]+$/)?.length),\n\toptions: z.any()\n});\n\nexport const DatasourceSpecSchema = DatasourceSpecFileSchema.extend({\n\t// queries: z.array(DatasourceQuerySchema),\n\tsourceDirectory: z.string()\n});\n\nexport const DatasourceQueryResultSchema = z.object({\n\tsource: DatasourceQuerySchema,\n\tresult: QueryResultSchema,\n\tname: z.string({ description: 'Output Table / Store name' })\n});\n\nexport const DatasourceCacheSchema = z.record(z.record(z.string().or(z.null())));\n\nexport const DatasourceManifestSchema = z.object({\n\trenderedFiles: z.record(z.array(z.string()))\n});\n","import { z } from 'zod';\n\n// Note that this only validates that the first item in the array\n// is a record with string keys. If the connector returns some\n// inconsistent array (e.g. [{}, 1]), it will not detect the\n// invalid row.\nconst QueryResultArraySchema = z.any().refine(\n\t(data) => {\n\t\t// result is not an array, fail\n\t\tif (!Array.isArray(data)) return false;\n\t\t// result has no rows, we can't validate this\n\t\t// but this is a correct result set\n\t\tif (data.length === 0) return true;\n\t\treturn z.record(z.string(), z.any()).safeParse(data[0]).success;\n\t},\n\t{ message: 'Data connector returned invalid rows' }\n);\nconst QueryResultGeneratorSchema = z.function();\n\nexport const QueryResultSchema = z\n\t.object({\n\t\t// Note that this only validates that the first item in the array\n\t\t// is a record with string keys. If the connector returns some\n\t\t// inconsistent array (e.g. [{}, 1]), it will not detect the\n\t\t// invalid row.\n\t\trows: QueryResultArraySchema.or(QueryResultGeneratorSchema),\n\t\tcolumnTypes: z.array(\n\t\t\tz.object({\n\t\t\t\tname: z.string(),\n\t\t\t\tevidenceType: z.enum(['boolean', 'number', 'string', 'date']),\n\t\t\t\ttypeFidelity: z.union([z.literal('precise'), z.literal('inferred')])\n\t\t\t})\n\t\t),\n\t\texpectedRowCount: z.number().optional()\n\t})\n\t.refine(\n\t\t(data) => {\n\t\t\t// We can't dig into generator functions\n\t\t\tif (typeof data.rows === 'function') return true;\n\n\t\t\tconst rows = data.rows;\n\n\t\t\t// Validate that all columnTypes appear\n\t\t\tif (rows.length) {\n\t\t\t\t// Filter to column types where name is not in row\n\t\t\t\t// Then map columnTypes to their names to make things easier\n\t\t\t\t// If there are any columns that were not filtered out; provide an error to zod\n\t\t\t\tconst missingColumns = data.columnTypes\n\t\t\t\t\t.filter((ct) => !(ct.name in rows[0]))\n\t\t\t\t\t.map((ct) => ct.name);\n\n\t\t\t\tif (missingColumns.length) {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn true;\n\t\t},\n\t\t(data) => {\n\t\t\t// We can't dig into generator functions\n\t\t\tif (typeof data.rows === 'function')\n\t\t\t\treturn {\n\t\t\t\t\tpath: ['columnTypes']\n\t\t\t\t};\n\t\t\tconst rows = data.rows;\n\n\t\t\tconst missingColumns = data.columnTypes\n\t\t\t\t.filter((ct) => !(ct.name in rows[0]))\n\t\t\t\t.map((ct) => ct.name);\n\t\t\treturn {\n\t\t\t\tpath: ['columnTypes'],\n\t\t\t\tmessage: `Datasource result has columns declared that are missing from results: ${missingColumns.join(\n\t\t\t\t\t', '\n\t\t\t\t)}`\n\t\t\t};\n\t\t}\n\t)\n\t.refine(\n\t\t(data) => {\n\t\t\t// We can't dig into generator functions\n\t\t\tif (typeof data.rows === 'function') return true;\n\n\t\t\t// Validate that all columns in the returned rows have declared column types\n\t\t\tif (data.rows.length) {\n\t\t\t\tconst colNames = data.columnTypes.map((ct) => ct.name);\n\t\t\t\tconst extraColumns = Object.keys(data.rows[0]).filter(\n\t\t\t\t\t(rowKey) => !colNames.includes(rowKey)\n\t\t\t\t);\n\t\t\t\tif (extraColumns.length) {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn true;\n\t\t},\n\t\t(data) => {\n\t\t\t// We can't dig into generator functions\n\t\t\tif (typeof data.rows === 'function')\n\t\t\t\treturn {\n\t\t\t\t\tpath: ['rows']\n\t\t\t\t};\n\n\t\t\tconst colNames = data.columnTypes.map((ct) => ct.name);\n\t\t\tconst extraColumns = Object.keys(data.rows[0]).filter((rowKey) => !colNames.includes(rowKey));\n\t\t\treturn {\n\t\t\t\tpath: ['rows'],\n\t\t\t\tmessage: `First row of results columns not provided in columnTypes: ${extraColumns.join(\n\t\t\t\t\t', '\n\t\t\t\t)}`\n\t\t\t};\n\t\t}\n\t);\n\nexport const QueryRunnerSchema = z\n\t.function()\n\t.args(\n\t\tz.string({ description: 'QueryString' }).or(z.null({ description: 'ExceededSizeQueryString' })),\n\t\tz.string({ description: 'QueryFilepath' }),\n\t\tz.number({ description: 'Batch Size' }).or(z.null())\n\t)\n\t.returns(z.promise(QueryResultSchema.or(z.null())).or(QueryResultSchema));\n\nexport const ConnectionTesterSchema = z\n\t.function()\n\t.args(z.any({ description: 'Connection Options' }))\n\t.returns(z.promise(z.union([z.literal(true), z.object({ reason: z.string() })])));\n\nexport const DatasourceConnectorFactorySchema = z\n\t.function()\n\t.args(\n\t\tz.any({ description: 'Connection Options' }),\n\t\tz.string({ description: 'Datasource directory' })\n\t)\n\t.returns(z.promise(QueryRunnerSchema));\n\n/**\n * @typedef {Object} IDatasourceOptionSpecSchema\n * @property {string} title\n * @property {'string' | 'number' | 'boolean' | 'select' | 'file'} type\n * @property {boolean} [secret]\n * @property {boolean} [shown]\n * @property {string} [description]\n * @property {boolean} [virtual]\n * @property {boolean} [nest]\n * @property {string | number | boolean | undefined} [default]\n * @property {Record<string | number | symbol, Record<string, IDatasourceOptionSpecSchema>> | undefined} [children]\n */\n\nconst primitive = z.union([z.string(), z.number(), z.boolean()]);\n\n/** @type {z.ZodRecord<z.ZodType<string>, z.ZodType<IDatasourceOptionSpecSchema>>} */\nexport const DatasourceOptionSpecSchema = z.record(\n\tz.string(),\n\tz.object({\n\t\ttitle: z.string(),\n\t\ttype: z.enum(['string', 'number', 'boolean', 'select', 'file']),\n\t\tsecret: z.boolean().default(false),\n\t\tshown: z.boolean().optional(),\n\t\t/**\n\t\t * Indicates that the field should not actually be persisted. Should be combined with `references`\n\t\t */\n\t\tvirtual: z.boolean().default(false),\n\t\t/**\n\t\t * Indicates that the field should get its value from another field if it is available\n\t\t */\n\t\treferences: z.string().optional(),\n\t\t/**\n\t\t * Indicates that the field can only get its value from the references\n\t\t */\n\t\tforceReference: z.boolean().default(false),\n\t\tfileFormat: z.enum(['json', 'yaml']).optional(),\n\t\tdescription: z.string().optional(),\n\t\tchildren: z.lazy(() => z.record(z.string(), DatasourceOptionSpecSchema)).optional(),\n\t\trequired: z.boolean().default(false),\n\t\toptions: z\n\t\t\t.union([z.string(), z.object({ value: primitive, label: z.string() })])\n\t\t\t.array()\n\t\t\t.optional(),\n\t\tnest: z.boolean().optional(),\n\t\tdefault: primitive.optional()\n\t})\n);\n\nexport const DatasourceConnectorSchema = z.object({\n\tgetRunner: DatasourceConnectorFactorySchema,\n\tsupports: z.array(z.union([z.string(), z.array(z.string())])),\n\toptions: DatasourceOptionSpecSchema,\n\ttestConnection: ConnectionTesterSchema,\n\tprocessSource: z\n\t\t.function()\n\t\t.returns(\n\t\t\tz.custom((d) => d && typeof d === 'object' && Symbol.asyncIterator in d, {\n\t\t\t\tmessage: 'Expected AsyncIterator result'\n\t\t\t})\n\t\t)\n\t\t.optional()\n});\n","/**\n * Renames the '_errors' property to 'errors' in the given object and its nested objects recursively.\n * It also removes any empty errors arrays\n *\n * @param {any} obj - The object to rename the '_errors' property in.\n * @return {Object} The object with the renamed property.\n */\nexport function cleanZodErrors(obj) {\n\tfor (const key in obj) {\n\t\tif (typeof obj[key] === 'object') {\n\t\t\tcleanZodErrors(obj[key]); // recursively traverse nested objects\n\t\t}\n\t\tif (key === '_errors') {\n\t\t\tif (obj['_errors'].length) {\n\t\t\t\t// De-duplicate\n\t\t\t\tobj['errors'] = Array.from(new Set(obj['_errors']));\n\t\t\t}\n\t\t\tdelete obj['_errors'];\n\t\t}\n\t}\n\treturn obj;\n}\n","/**\n * Encodes a value or an array of values into Base64 recursively.\n * @param {*} v - The value or array of values to encode.\n * @returns {*} - The encoded value or array of values.\n */\nexport const encodeBase64Deep = (v) => {\n\tif (Array.isArray(v)) {\n\t\tconst mapped = v.map(encodeBase64Deep);\n\t\treturn mapped;\n\t} else if (typeof v === 'string') {\n\t\treturn btoa(v);\n\t} else if (v && v.constructor === Object) {\n\t\t// bare object\n\t\treturn Object.fromEntries(\n\t\t\tObject.entries(v).map(\n\t\t\t\t/**\n\t\t\t\t * Maps each key-value pair of the object.\n\t\t\t\t * @param {[string, object]} entry - The key-value pair.\n\t\t\t\t * @returns {[string, object|string]} - The encoded key-value pair.\n\t\t\t\t */\n\t\t\t\t([k, v]) => [k, encodeBase64Deep(v)]\n\t\t\t)\n\t\t);\n\t} else {\n\t\treturn v;\n\t}\n};\n\n/**\n * Dencodes a value or an array of values from Base64 recursively.\n * @param {*} v - The value or array of values to encode.\n * @returns {*} - The encoded value or array of values.\n */\nexport const decodeBase64Deep = (v) => {\n\tif (Array.isArray(v)) {\n\t\tconst mapped = v.map(decodeBase64Deep);\n\t\treturn mapped;\n\t} else if (typeof v === 'string') {\n\t\treturn atob(v);\n\t} else if (v && v.constructor === Object) {\n\t\t// bare object\n\t\treturn Object.fromEntries(\n\t\t\tObject.entries(v).map(\n\t\t\t\t/**\n\t\t\t\t * Maps each key-value pair of the object.\n\t\t\t\t * @param {[string, object]} entry - The key-value pair.\n\t\t\t\t * @returns {[string, object|string]} - The encoded key-value pair.\n\t\t\t\t */\n\t\t\t\t([k, v]) => [k, decodeBase64Deep(v)]\n\t\t\t)\n\t\t);\n\t} else {\n\t\treturn v;\n\t}\n};\n","import { discoverEvidencePlugins } from '../plugin-discovery';\nimport { buildConnector } from './build-connector';\nimport chalk from 'chalk';\nimport path from 'path';\n/**\n * @param {EvidenceConfig} [cfg]\n * @param {PackageDiscoveryResult} [discoveries] Optional: Pass in already discovered plugins\n * @returns {Promise<PluginDatasources>}\n */\nexport async function getDatasourcePlugins(cfg, discoveries) {\n\tconst pluginDiscoveries = discoveries ?? (await discoverEvidencePlugins());\n\n\treturn await pluginDiscoveries.datasources.reduce(\n\t\t/**\n\t\t * Adds a plugin to a map of EvidencePluginPackages with a corresponding DatasourceConnectorFactory,\n\t\t * ensuring that no duplicate datasources are added.\n\t\t * @param {Promise<Record<string, PluginDatasources[string]>>} _acc - A promise representing the current state of the package map\n\t\t * @param {EvidencePluginPackage<EvidenceDatasourcePackage>} v - The plugin package to be added to the map\n\t\t * @returns {Promise<Record<string, PluginDatasources[string]>>} - A promise representing the updated package map\n\t\t */\n\t\tasync (_acc, v) => {\n\t\t\t// TODO: Handle Overrides\n\n\t\t\t// Wait for the current state of the package map to resolve\n\t\t\tconst acc = await _acc;\n\t\t\t// Build a DatasourceConnectorFactory for the plugin package's datasourcess\n\t\t\tconst factory = await buildConnector(\n\t\t\t\tpath.join(v.path, v.package.main),\n\t\t\t\tv.package.evidence?.datasources ?? [],\n\t\t\t\tv.package.name\n\t\t\t);\n\t\t\t// For each datasource in the plugin package...\n\t\t\tv.package.evidence.datasources?.flat().forEach((d) => {\n\t\t\t\t// If a plugin with the same datasource already exists in the map, throw an error\n\t\t\t\tif (d in acc) {\n\t\t\t\t\tconsole.error(\n\t\t\t\t\t\tchalk.red(\n\t\t\t\t\t\t\t`[!] Multiple datasource connectors found for ${d}. Please ensure that only one is used.`\n\t\t\t\t\t\t)\n\t\t\t\t\t);\n\t\t\t\t\tthrow new Error('Datasource plugin conflict found!');\n\t\t\t\t}\n\t\t\t\t// Otherwise, add the plugin package and its DatasourceConnectorFactory to the map\n\t\t\t\tacc[d] = {\n\t\t\t\t\tpackage: v,\n\t\t\t\t\tfactory: factory.getRunner,\n\t\t\t\t\toptions: factory.options,\n\t\t\t\t\ttestConnection: factory.testConnection,\n\t\t\t\t\tprocessSource: /** @type {*} **/ (factory.processSource) // We can't really validate AsyncIterator output\n\t\t\t\t};\n\t\t\t});\n\t\t\t// Return the updated package map as a promise\n\t\t\treturn acc;\n\t\t},\n\t\tPromise.resolve({})\n\t);\n}\n","import { getRootModules } from './get-root-modules';\nimport { resolveEvidencePackages } from './resolve-evidence-config';\n\n/**\n * @param {string} [rootDir]\n * @returns {Promise<PackageDiscoveryResult>}\n * @this {void}\n */\nexport async function discoverEvidencePlugins(rootDir) {\n\tif (!rootDir) rootDir = await getRootModules();\n\n\treturn await resolveEvidencePackages(rootDir);\n}\n","import path from 'path';\nimport fs from 'fs/promises';\n\n/**\n * @param {string} p\n * @returns {Promise<boolean>}\n */\nconst hasNodeModules = async (p) => {\n\tconst directoryItems = await fs.readdir(p);\n\treturn directoryItems.includes('node_modules');\n};\n\n/**\n * Attempts to find the highest, project-scoped node_modules filepath.\n * Note that this behavior _should_ remain the same regardless of where this is run from\n * Locally installed (\"linked\") packages and regularly installed packages should return the same value.\n * @param {string | undefined} [startingPoint]\n * @returns {Promise<string>}\n */\nexport const getRootModules = async (startingPoint) => {\n\t// Either use the entry file or a specific startingPoint\n\tconst entryFile = startingPoint ?? process.cwd();\n\t// Split the entryfile path on \"node_modules\", this will help if the main file is nested\n\t// e.g. if sveltekit, main file will be node_modules/@sveltejs/kit/node_modules\n\t// node_modules/.pnpm/vite@4.0.4/node_modules/vite/bin/vite.js\n\tconst parsedPath = path.parse(entryFile.split('/node_modules')[0]);\n\tlet p = `${parsedPath.dir}/${parsedPath.base}`;\n\tconst initP = p;\n\tconst stat = await fs.stat(p);\n\tif (stat.isFile()) p = path.parse(p).dir;\n\n\twhile (!(await hasNodeModules(p))) {\n\t\tif (p === path.parse(p).root) {\n\t\t\tthrow new Error(`Could not locate node_modules! ${JSON.stringify({ startingPoint, initP })}`);\n\t\t}\n\t\tp = path.parse(p).dir;\n\t}\n\n\treturn p;\n};\n","import { isValidPackage } from './is-valid-package';\nimport path from 'path';\nimport { loadConfig } from './load-config';\n/**\n * Wrapper function to create a package validator function\n * @param {string} rootDir\n * @returns {(packageName: string) => Promise<EvidencePluginPackage<ValidPackage> | false>}\n */\nconst validatePlugin =\n\t(rootDir) =>\n\t/**\n\t * Validates that the given package name exists and is a valid plugin package\n\t * @param {string} packageName\n\t * @returns {Promise<EvidencePluginPackage<ValidPackage> | false>}\n\t */\n\tasync (packageName) => {\n\t\tconst packagePath = path.resolve(rootDir, 'node_modules', packageName);\n\t\tconst validPackage = await isValidPackage(packagePath);\n\t\tif (!validPackage) return false;\n\t\treturn {\n\t\t\tpackage: validPackage,\n\t\t\tpath: packagePath\n\t\t};\n\t};\n\n/**\n * Leverages evidence.plugins.yaml to resolve plugins\n * @param {string} rootDir\n * @returns {Promise<PackageDiscoveryResult>}\n */\nexport const resolveEvidencePackages = async (rootDir) => {\n\t/** @type {EvidenceConfig} */\n\tconst configContent = loadConfig(rootDir);\n\n\t/** @type {EvidencePluginPackage<ValidPackage>[]} */\n\tconst componentPackages = await Promise.all(\n\t\tObject.keys(configContent.components).map(validatePlugin(rootDir))\n\t).then((pack) => /** @type {Exclude<typeof pack[number], false>[]} */ (pack.filter(Boolean)));\n\n\t/** @type {EvidencePluginPackage<EvidenceDatasourcePackage>[]} */\n\tconst datasourcePackages = await Promise.all(\n\t\tObject.keys(configContent.datasources).map(validatePlugin(rootDir))\n\t).then(\n\t\t(pack) =>\n\t\t\t/** @type {EvidencePluginPackage<EvidenceDatasourcePackage>[]} */\n\t\t\t(pack.filter((p) => p && Boolean(p.package.evidence?.datasources)))\n\t);\n\n\treturn {\n\t\tcomponents: componentPackages,\n\t\tdatasources: datasourcePackages\n\t};\n};\n","import chalk from 'chalk';\nimport { ValidPackageSchema } from './schemas/evidence-package.schema';\nimport fs from 'fs/promises';\nimport { cleanZodErrors } from '../lib/clean-zod-errors';\n/**\n * Checks a directory to see if it is a package\n * and if it is a package, if it includes\n * the evidence block that marks it as a plugin\n * @param {string} path\n * @returns {Promise<false | ValidPackage>}\n */\nexport const isValidPackage = async (path) => {\n\ttry {\n\t\tconst s = await fs.stat(path);\n\t\tif (!s.isDirectory()) return false;\n\t} catch (e) {\n\t\tif (e instanceof Error && /** @type{NodeJS.ErrnoException} */ (e).code !== 'ENOENT') {\n\t\t\tconsole.warn(\n\t\t\t\tchalk.yellow(\n\t\t\t\t\t`[!] An error occured while loading ${chalk.bold(\n\t\t\t\t\t\t`\"${path.split('node_modules/')[1]}\"`\n\t\t\t\t\t)}: ${e}.`\n\t\t\t\t)\n\t\t\t);\n\t\t} else {\n\t\t\tconsole.warn(\n\t\t\t\tchalk.yellow(\n\t\t\t\t\t`[!] ${chalk.bold(\n\t\t\t\t\t\t`\"${path.split('node_modules/')[1]}\"`\n\t\t\t\t\t)} could not be found in your node_modules. Check for spelling errors or try running npm install.`\n\t\t\t\t)\n\t\t\t);\n\t\t}\n\t\treturn false;\n\t}\n\n\tconst c = await fs.readdir(path);\n\tif (!c.includes('package.json')) return false;\n\n\tconst packageContent = await fs.readFile(`${path}/package.json`).then(\n\t\t/** @param {Buffer} fileContent */\n\t\t(fileContent) => JSON.parse(fileContent.toString())\n\t);\n\tconst zodResult = ValidPackageSchema.safeParse(packageContent);\n\tif (zodResult.success) return zodResult.data;\n\telse {\n\t\tconsole.warn(\n\t\t\tchalk.yellow(\n\t\t\t\t`[!] ${chalk.bold(`\"${path.split('node_modules/')[1]}\"`)} could not be loaded as a plugin`\n\t\t\t)\n\t\t);\n\t\tconsole.warn(cleanZodErrors(zodResult.error.format()));\n\t\treturn false;\n\t}\n};\n","import { z } from 'zod';\n\nconst PackageExportSchema = z.union([\n\tz.object({ main: z.string() }, { description: 'Use the main field of the package.json' }),\n\tz.object(\n\t\t{ exports: z.object({ '.': z.string() }) },\n\t\t{ description: 'Use the exports field of the package.json' }\n\t),\n\tz\n\t\t.object({ svelte: z.string() }, { description: 'Use the svelte field of the package.json' })\n\t\t.optional()\n]);\n\nconst BasePackageSchema = z.object({\n\tname: z.string(),\n\tevidence: z.undefined()\n});\n\nexport const GenericPackageSchema = z.intersection(BasePackageSchema, PackageExportSchema);\n\nexport const EvidencePackageSchema = z.intersection(\n\tBasePackageSchema.extend({\n\t\tevidence: z.object({\n\t\t\tcomponents: z.boolean().optional(),\n\t\t\tdatasources: z.array(z.union([z.string(), z.array(z.string())])).optional(),\n\t\t\ticon: z.string().optional()\n\t\t})\n\t}),\n\tPackageExportSchema\n);\n\nexport const ValidPackageSchema = z.union([GenericPackageSchema, EvidencePackageSchema]);\n","import { cleanZodErrors } from '../lib/clean-zod-errors';\nimport chalk from 'chalk';\nimport fs from 'fs';\nimport yaml from 'yaml';\nimport { EvidenceConfigSchema } from './schemas/evidence-config.schema';\n\n/**\n * @param {string} rootDir\n * @returns {EvidenceConfig}\n */\nexport const loadConfig = (rootDir) => {\n\tconst configPath = `${rootDir}/evidence.plugins.yaml`;\n\ttry {\n\t\tconst configFileContent = fs.readFileSync(configPath, 'utf8').toString();\n\t\t// Surround all YAML key that begin with \"@\" in quotes\n\t\t// Skipping keys that are already quoted (e.g. beginning of line or whitespace)\n\t\tconst rawConfig = yaml.parse(configFileContent.replaceAll(/($|\\s)(@.+):/g, '$1\"$2\":'));\n\n\t\tconst configResult = EvidenceConfigSchema.safeParse(rawConfig);\n\t\tif (!configResult.success) {\n\t\t\tconsole.error(\n\t\t\t\tchalk.bold.red(\n\t\t\t\t\t`[!] evidence.plugins.yaml does not contain a valid configuration. \\n    Plugins will not be loaded. This may lead to unexpected behavior.`\n\t\t\t\t)\n\t\t\t);\n\t\t\tconst formattedError = cleanZodErrors(configResult.error.format());\n\t\t\tconsole.error(chalk.red('|   Discovered Errors:'));\n\t\t\tconst redPipe = chalk.red('|');\n\t\t\tconsole.error(\n\t\t\t\t`${redPipe}   ${yaml.stringify(formattedError).replace(/\\n/g, `\\n${redPipe}   `)}`\n\t\t\t);\n\t\t\tthrow new Error('Invalid evidence.plugins.yaml');\n\t\t}\n\n\t\treturn configResult.data;\n\t} catch (e) {\n\t\tif (!(e instanceof Error)) throw e;\n\t\tif (e.message.startsWith('ENOENT')) {\n\t\t\tthrow new Error(`Could not find evidence plugins file. (Look at ${configPath})`, {\n\t\t\t\tcause: e\n\t\t\t});\n\t\t}\n\t\tthrow e;\n\t}\n};\n","import { z } from 'zod';\n\nexport const EvidenceComponentConfigSchema = z.object({\n\toverrides: z.array(z.string()).default([]),\n\taliases: z\n\t\t.record(\n\t\t\tz.string({ description: 'Component Name' }),\n\t\t\tz.string({ description: 'Alias to apply' })\n\t\t)\n\t\t.default({}),\n\n\tprovides: z.array(z.string()).default([])\n});\n\nexport const EvidenceDatasourceConfigSchema = z.object({\n\toverrides: z.array(z.string()).default([])\n});\n\nexport const EvidenceConfigSchema = z\n\t.object({\n\t\tcomponents: z.record(z.string(), EvidenceComponentConfigSchema),\n\t\tdatasources: z\n\t\t\t.record(z.string({ description: 'Plugin Package Name' }), EvidenceDatasourceConfigSchema)\n\t\t\t.default({})\n\t})\n\t.nonstrict();\n","import chalk from 'chalk';\nimport yaml from 'yaml';\nimport { cleanZodErrors } from '../lib/clean-zod-errors';\nimport { DatasourceConnectorSchema } from './schemas/query-runner.schema';\n/**\n * Builds a datasource connector with the given package main and support types.\n *\n * @param {string} packageMain - The main file of the package to import.\n * @param {(string | string[])[]} supports - An array of support types.\n * @param {string} packageName - Name of the connector package; used for error outputs\n * @return {Promise<DatasourceConnector>} A promise that resolves to the built datasource connector.\n */\nexport const buildConnector = async (packageMain, supports, packageName) => {\n\t// https://github.com/nodejs/node/issues/31710 thanks windows\n\tconst crossPlatformPackage = new URL(`file:///${packageMain}`).href;\n\tconst connectorPackage = await import(crossPlatformPackage /* @vite-ignore */);\n\tconst connector = DatasourceConnectorSchema.safeParse({ ...connectorPackage, supports });\n\n\tif (!connector.success) {\n\t\tconsole.error(chalk.bold.red(`[!] Datasource connector \"${packageName}\" is invalid`));\n\t\tconst formattedError = cleanZodErrors(connector.error.format());\n\t\tconsole.error(chalk.red('|   Discovered Errors:'));\n\t\tconst redPipe = chalk.red('|');\n\t\tconsole.error(\n\t\t\t`${redPipe}   ${yaml.stringify(formattedError).replace(/\\n/g, `\\n${redPipe}   `)}`\n\t\t);\n\t\tprocess.exit(1);\n\t} else {\n\t\treturn connector.data;\n\t}\n};\n"],"names":["Command","$kIqch$Command","$kIqch$fspromises","$kIqch$path","$kIqch$yaml","$kIqch$chalk","$kIqch$lodashmerge","z","$kIqch$z","$kIqch$fs","$20af1336d074baeb$var$QueryResultArraySchema","any","refine","data","Array","isArray","length","record","string","safeParse","success","message","$20af1336d074baeb$var$QueryResultGeneratorSchema","function","$20af1336d074baeb$export$c959e5da37fd983b","object","rows","or","columnTypes","array","name","evidenceType","enum","typeFidelity","union","literal","expectedRowCount","number","optional","missingColumns","filter","ct","map","path","join","colNames","extraColumns","Object","keys","rowKey","includes","$20af1336d074baeb$export$f5ddb356b686dd84","args","description","null","returns","promise","$20af1336d074baeb$export$989ca211935133de","reason","$20af1336d074baeb$export$a0e9703f15a2290c","$20af1336d074baeb$var$primitive","boolean","$20af1336d074baeb$export$7b12d43aed3b0368","title","type","secret","default","shown","virtual","references","forceReference","fileFormat","children","lazy","required","options","value","label","nest","$20af1336d074baeb$export$4f0eb8607c96bd68","getRunner","supports","testConnection","processSource","custom","d","Symbol","asyncIterator","$b1927a7a8d2c2fb9$export$89c81f16bad71a6b","filepath","content","hash","$b1927a7a8d2c2fb9$export$e0cbf1bbd256fc2f","s","toString","match","$579fd89ba5cae013$export$71e7d3deffa0730b","obj","key","from","Set","extend","sourceDirectory","source","result","renderedFiles","$41db863454cd88ad$export$1867e32d63096a84","v","btoa","constructor","fromEntries","entries","k","$41db863454cd88ad$export$d5bf8907c6ddf98a","atob","$9fbfd3d9d29e05b1$export$46a3b0a4d36b05de","create","pwd","resolve","sourcesDir","contents","readdir","withFileTypes","find","c","isDirectory","sourceDirPath","console","warn","yellow","mkdir","recursive","info","green","$9fbfd3d9d29e05b1$export$4d546bd0a30a867d","sourceName","out","keyRegex","process","env","parts","exec","toLowerCase","startsWith","rawOptKey","substring","split","t","forEach","i","$9fbfd3d9d29e05b1$export$5f9bc633b116660f","sourcesDirectories","Promise","all","dirName","sourceDir","possibleDir","stat","connParams","$9fbfd3d9d29e05b1$var$loadConnectionConfiguration","sep","pop","Error","$9fbfd3d9d29e05b1$var$loadConnectionOptions","then","r","Boolean","connParamsUnchecked","connParamsRaw","readFile","catch","e","parse","cause","validationResult","error","bold","red","formattedError","format","redPipe","stringify","replace","optionsFilePath","optionsFile","$0d9f24ac34045674$var$hasNodeModules","p","directoryItems","$0d9f24ac34045674$export$6de9f17ef8a8b7d7","startingPoint","entryFile","cwd","parsedPath","dir","base","initP","isFile","root","JSON","$850532d8e21c1276$var$PackageExportSchema","main","exports","svelte","$850532d8e21c1276$var$BasePackageSchema","evidence","undefined","$850532d8e21c1276$export$a14d030d75ef573c","intersection","$850532d8e21c1276$export$bca9d2c38fe4cf42","components","datasources","icon","$850532d8e21c1276$export$ac6197b8a56da2df","$ac2929749a5ac42a$export$f8dc70b6d32541e2","code","packageContent","fileContent","zodResult","$04d4158f42678bf5$export$797917169e2ec068","overrides","aliases","provides","$04d4158f42678bf5$export$81ab33ffc20a47da","$04d4158f42678bf5$export$e691085fbd9bf5be","nonstrict","$682b92d065baf95f$export$c1a4367d4847eb06","rootDir","configPath","configFileContent","readFileSync","rawConfig","replaceAll","configResult","$15f09b06c8f2a17d$var$validatePlugin","packageName","packagePath","validPackage","package","$15f09b06c8f2a17d$export$4b0a2a49a61b15e5","configContent","pack","$4772adaeeb479286$export$9418d811d68624a6","$200a5e7a6f294d86$export$ebbe0f536b18196e","packageMain","crossPlatformPackage","URL","href","connectorPackage","connector","exit","$f24b7cd857e13d65$export$8fbb278aab496aa6","cfg","discoveries","pluginDiscoveries","reduce","_acc","acc","factory","flat","$444c6539df4427ec$var$program","command","action","log","datasourceDir"],"version":3,"file":"cli.js.map","sourceRoot":"../../../../"}